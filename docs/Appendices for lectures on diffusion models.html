<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Laura Sánchez García">
<meta name="author" content="Julio Antonio Soto Vicente">
<meta name="dcterms.date" content="2024-11-05">
<meta name="description" content="Appendices for lectures on diffusion models at IE university (C4_466671 - Advanced Artificial Intelligence)">

<title>Appendices for lectures on diffusion models – C4_466671 - Diffusion models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Appendices for lectures on diffusion models – C4_466671 - Diffusion models">
<meta property="og:description" content="Lectures on diffusion models at IE university (C4_466671 - Advanced Artificial Intelligence)">
<meta property="og:image" content="https://julioasotodv.github.io/ie-c4-466671-diffusion-models/images/sdxl_polarbear_og.png">
<meta property="og:site_name" content="C4_466671 - Diffusion models">
<meta property="og:image:height" content="630">
<meta property="og:image:width" content="1200">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">C4_466671 - Diffusion models</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/julioasotodv/ie-C4-466671-diffusion-models" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#a.-the-nice-property" id="toc-a.-the-nice-property" class="nav-link active" data-scroll-target="#a.-the-nice-property">A. The Nice™ property</a></li>
  <li><a href="#b.-diffusion-loss-function-elbo-derivation" id="toc-b.-diffusion-loss-function-elbo-derivation" class="nav-link" data-scroll-target="#b.-diffusion-loss-function-elbo-derivation">B. Diffusion loss function: ELBO derivation</a>
  <ul class="collapse">
  <li><a href="#b.1.-vae-loss" id="toc-b.1.-vae-loss" class="nav-link" data-scroll-target="#b.1.-vae-loss">B.1. VAE loss</a></li>
  <li><a href="#b.2.-ddpm-loss" id="toc-b.2.-ddpm-loss" class="nav-link" data-scroll-target="#b.2.-ddpm-loss">B.2. DDPM loss</a></li>
  </ul></li>
  <li><a href="#c.-the-forward-process-posterior" id="toc-c.-the-forward-process-posterior" class="nav-link" data-scroll-target="#c.-the-forward-process-posterior">C. The <em>forward process posterior</em></a></li>
  <li><a href="#d.-objective-the-training-procedure" id="toc-d.-objective-the-training-procedure" class="nav-link" data-scroll-target="#d.-objective-the-training-procedure">D. Objective &amp; the training procedure</a></li>
  <li><a href="#e.-the-sampling-procedure" id="toc-e.-the-sampling-procedure" class="nav-link" data-scroll-target="#e.-the-sampling-procedure">E. The sampling procedure</a>
  <ul class="collapse">
  <li><a href="#e.1.-the-mathematical-answer" id="toc-e.1.-the-mathematical-answer" class="nav-link" data-scroll-target="#e.1.-the-mathematical-answer">E.1. The mathematical answer</a></li>
  <li><a href="#e.2.-the-intuitive-answer" id="toc-e.2.-the-intuitive-answer" class="nav-link" data-scroll-target="#e.2.-the-intuitive-answer">E.2. The intuitive answer</a></li>
  </ul></li>
  <li><a href="#citation" id="toc-citation" class="nav-link" data-scroll-target="#citation">Citation</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Appendices for lectures on diffusion models</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Authors</div>
  <div class="quarto-title-meta-heading">Affiliations</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Julio Antonio Soto Vicente <a href="mailto:%6Au%6C%69oantonio.soto%76icente@%67mai%6C.%63om" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Sandoz Farmacéutica, S.A.
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 5, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p><br><br> This document accompanies the slides available <a href="get_slides_handout.html" target="blank">here</a></p>
<section id="a.-the-nice-property" class="level1">
<h1>A. The Nice™ property</h1>
<p>This property allows us to <em>jump</em> to any <span class="math inline">\(\mathbf{x}_t\)</span> (noisy image at timestep <span class="math inline">\(t\)</span>) directly from <span class="math inline">\(\mathbf{x}_0\)</span> (original image) without having to compute any intermediate steps. To understand where it comes from, let’s recover first the forward process equation:</p>
<p><span class="math display">\[q(\mathbf{x}_t \mid \mathbf{x}_{t-1}) \coloneqq \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I}) \tag{1}\label{1}\]</span></p>
<p>As seen in slide 14 and Equation <span class="math inline">\((2)\)</span> of the <a href="https://arxiv.org/abs/2006.11239" target="_blank">DDPM paper</a>. <span class="math inline">\(\mathbf{I}\)</span> is the identity matrix, which basically indicates that the <a href="https://julioasotodv.github.io/interactive-demos/mvn/multivariate_normal.html" target="_blank">multivariate Normal</a> distribution is isotropic (only the main diagonal has nonzero values, as <span class="math inline">\(\mathbf{I}\)</span> is multiplied by <span class="math inline">\(\beta_t\)</span>, yielding the covariance matrix of the Normal). In a nutshell, an isotropic Normal distribution is the one in which all the covariances between its dimensions are 0. Therefore, all its dimensions are independent from each other. <br><br></p>
<p>Now, let’s define two additional variables that will become handy. We will define:</p>
<p><span class="math display">\[\alpha_t \coloneqq 1 - \beta_t \tag{2} \label{2}\]</span></p>
<p>And</p>
<p><span class="math display">\[\bar\alpha_t \coloneqq \prod_{s=1}^t{\alpha_s} \tag{3} \label{3}\]</span></p>
<p><span class="math inline">\(\alpha_t\)</span> is self-explanatory. As for <span class="math inline">\(\bar\alpha_t\)</span>, it’s just the product of all <span class="math inline">\(\alpha\)</span>s from the first one (<span class="math inline">\(\alpha_1\)</span>) up to <span class="math inline">\(\alpha_t\)</span>. For instance: <span class="math inline">\(\bar\alpha_4 = \alpha_1 \cdot \alpha_2 \cdot \alpha_3 \cdot \alpha_4\)</span> <br><br></p>
<p>With that in mind, now let’s express <span class="math inline">\(\mathbf{x}_t\)</span> as a transformation instead of as the Normal probability distribution <span class="math inline">\(q(\mathbf{x}_t \mid \mathbf{x}_{t-1})\)</span>. To do so, we can take advantage of the <a href="https://sassafras13.github.io/ReparamTrick/#the-math-behind-the-curtain" target="_blank">reparametrization trick for the Normal distribution</a>. In a nutshell, the reparametrization trick allows us to express a random variable <span class="math inline">\(z\)</span> from any Normal distribution (with any mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>) in terms of the Standard Normal <span class="math inline">\(\mathcal{N}(0, 1)\)</span>, which we will call <span class="math inline">\(\boldsymbol{\epsilon}\)</span> for simplicity, as follows:</p>
<p><span class="math display">\[z \sim \mathcal{N}(\mu, \sigma^2) \longrightarrow z = \mu + \sigma \cdot \boldsymbol{\epsilon},\qquad \boldsymbol{\epsilon} \sim \mathcal{N}(0, 1) \tag{4}\label{4}\]</span> <br> With the reparametrization trick from <span class="math inline">\(\eqref{4}\)</span> and the definition of <span class="math inline">\(\alpha_t\)</span> in <span class="math inline">\(\eqref{2}\)</span> we can now express <span class="math inline">\(\mathbf{x}_t\)</span> following <span class="math inline">\(\eqref{1}\)</span> as:</p>
<p><span class="math display">\[\begin{align}
\mathbf{x}_t &amp; = \sqrt{1 - \beta_t} \mathbf{x}_{t-1} + \sqrt{\beta} \boldsymbol{\epsilon} \\
\, \\
&amp; = \sqrt{\alpha_t} \mathbf{x}_{t-1} + \sqrt{1 - \alpha_t} \boldsymbol{\epsilon}
\end{align}\]</span> <br> As you may imagine, <span class="math inline">\(\mathbf{x}_{t-1}\)</span> can also be developed using the exact same formula, to be written in terms of <span class="math inline">\(\mathbf{x}_{t-2}\)</span>. Therefore, we can say:</p>
<p><span class="math display">\[\begin{align}
\mathbf{x}_{t} &amp; = \sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}\mathbf{x}_{t-2} + \sqrt{1- \alpha_{t-1}}\boldsymbol{\epsilon}) + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon} \\
&amp; \, \\
&amp; \text{multiplying:} \\
&amp; = \sqrt{\alpha_t}\sqrt{\alpha_{t-1}}\mathbf{x}_{t-2} + \sqrt{\alpha_t}\sqrt{1 - \alpha_{t-1}}\boldsymbol{\epsilon} + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon} \\
&amp; \, \\
&amp; \text{grouping square roots (remember that the product} \\
&amp; \text{of square roots is the square root of the product):} \\
&amp; = \sqrt{\alpha_t \alpha_{t-1}}\mathbf{x}_{t-2} + \sqrt{\alpha_t (1 - \alpha_{t-1})} \boldsymbol{\epsilon} + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon} \tag{5}\label{5}
\end{align}\]</span> <br> To simplify it, we can take advantage of <a href="https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables" target="_blank">a cool property of Normal distributions</a>, where the sum <span class="math inline">\(c\)</span> of two normally distributed random variables <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> can be expressed as another Normal distribution, as follows:</p>
<p><span class="math display">\[\displaylines{
a \sim \mathcal{N}(\mu_a, \sigma^2_a) \\
b \sim \mathcal{N}(\mu_b, \sigma^2_b) \\
c = a + b \\ \text{with}\\
c \sim \mathcal{N}(\mu_a + \mu_b, \, \sigma^2_a + \sigma^2_b)
}\]</span><br></p>
<p>Think for a second: if we apply the reparametrization trick <span class="math inline">\(\eqref{4}\)</span> in reverse we could say for instance that <span class="math inline">\(\sqrt{1 - \alpha_t}\epsilon \sim \mathcal{N}(0, (1 - \alpha_t)\mathbf{I})\)</span> (keep in mind what is standard deviation and what is variance!). With that in mind, we can now recover <span class="math inline">\(\eqref{5}\)</span>, apply the addition of two Normals and keep on developing it:</p>
<p><span class="math display">\[\begin{align}
\mathbf{x}_{t} &amp; = \sqrt{\alpha_t \alpha_{t-1}}\mathbf{x}_{t-2} + \sqrt{\alpha_t (1 - \alpha_{t-1})} \epsilon + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon} \\
&amp; \, \\
&amp; \text{addition of Normal random variables:} \\
&amp; = \sqrt{\alpha_t \alpha_{t-1}}\mathbf{x}_{t-2} + \sqrt{\alpha_t(1 - \alpha_{t-1}) + (1 - \alpha_t)}\boldsymbol{\epsilon} \\
&amp; \, \\
&amp; = \sqrt{\alpha_t \alpha_{t-1}}\mathbf{x}_{t-2} + \sqrt{\alpha_t - \alpha_t \alpha_{t-1} + 1 - \alpha_t}\boldsymbol{\epsilon} \\
&amp; \, \\
&amp; = \sqrt{\alpha_t \alpha_{t-1}}\mathbf{x}_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}}\boldsymbol{\epsilon} \\
\end{align}\]</span> <br> We can keep on recursively developing <span class="math inline">\(\mathbf{x}_{t-2}\)</span> in terms of <span class="math inline">\(\mathbf{x}_{t-3}\)</span> applying the exact same logic…</p>
<p><span class="math display">\[\begin{align}
\mathbf{x}_{t} &amp; = \sqrt{\alpha_t \alpha_{t-1}}\mathbf{x}_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}}\boldsymbol{\epsilon} \\
&amp; \, \\
&amp; = \sqrt{\alpha_t \alpha_{t-1} \alpha_{t-2}}\mathbf{x}_{t-3} + \sqrt{1 - \alpha_t \alpha_{t-1} \alpha_{t-2}}\boldsymbol{\epsilon}
\end{align}\]</span> <br> … And we could keep on, until we write everything in terms of only <span class="math inline">\(\mathbf{x}_0\)</span>. Doing so, we would get:</p>
<p><span class="math display">\[\mathbf{x}_t = \sqrt{\prod_{s=1}^t{\alpha_s}} \mathbf{x}_{0} + \sqrt{1 - \prod_{s=1}^t{\alpha_s}}\boldsymbol{\epsilon}\]</span> <br> And now we can apply the definition of <span class="math inline">\(\bar\alpha_t\)</span> in <span class="math inline">\(\eqref{3}\)</span> to rewrite it as:</p>
<p><span class="math display">\[\mathbf{x}_t = \sqrt{\bar\alpha_t} \mathbf{x}_{0} + \sqrt{1 - \bar\alpha_t}\boldsymbol{\epsilon}\]</span> <br> Finally, applying the reparametrization trick in reverse again we can state that:</p>
<p><span class="math display">\[q(\mathbf{x}_t \mid \mathbf{x}_{0}) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar\alpha_t} \mathbf{x}_0, (1- \bar\alpha_t) \mathbf{I}) \tag{6} \label{6}\]</span> <br> As seen in the Nice™ property slide and in Equation <span class="math inline">\((4)\)</span> of the DDPM paper. <br><br></p>
<hr>
</section>
<section id="b.-diffusion-loss-function-elbo-derivation" class="level1">
<h1>B. Diffusion loss function: ELBO derivation</h1>
<p>The DDPM model looks very similar to a Variational Autoencoder if you think of it, except for three <em>little</em> things:</p>
<ol type="1">
<li><p>We can think of a DDPM as a VAE where the forward diffusion process is the VAE encoder; and the reverse diffusion process is the VAE decoder. However, the forward diffusion process in a DDPM does not need to be learned by a neural network: we just set it up as a sequence of noise additions (as we have seen)</p></li>
<li><p>A VAE computes the latent space in a single step, whereas in DDPMs we perform many steps to reach there. However, there is a variant of VAEs that also involves many steps in an almost identical fashion to a DDPM, called MHVAEs (Markovian Hierarchical Variational Autoencoders). In fact, both forward and reverse processes in DDPM are <em>Markovian</em>, meaning that they follow the Markov property: in which the state of the noisy image at a specific timestep <span class="math inline">\(t\)</span> only depends on the state of the image in the immediately previous step (<span class="math inline">\(t-1\)</span> in the forward process and <span class="math inline">\(t+1\)</span> in the reverse process, respectively)</p></li>
<li><p>We can think of the fully noised image <span class="math inline">\(\mathbf{x}_T\)</span> in similar terms to a VAE’s <em>latent space</em> <span class="math inline">\(Z\)</span>. However, the latent space in VAEs has smaller dimensions than the original image, whereas in DDPMs the dimensions are the same as in the original image (same image height, width and channels)</p></li>
</ol>
<p>Other than that, both models are very similar. Therefore, we can try to express the loss function of a DDPM by building on the VAE one.</p>
<p><em>Note: There are more ways to get to the same loss function that we will end up with. By using different principles or slightly different definitions, we can still reach the same final equation. I say this because you may find different derivations online or in other books/papers. However, the final loss expression should be the same (or at least equivalent).</em> <br><br></p>
<section id="b.1.-vae-loss" class="level2">
<h2 class="anchored" data-anchor-id="b.1.-vae-loss">B.1. VAE loss</h2>
<p>At the end of the day, both in VAEs and in DDPMs we want our final generated image to be as accurate as possible. The most widely used concept to measure how well the generated output matches the training data is the <strong>likelihood</strong>.</p>
<p>Given a model with learnable weights/parameters <span class="math inline">\(\theta\)</span>, we can express the likelihood of the generated data <span class="math inline">\(\mathbf{x}\)</span> as <span class="math inline">\(p(\mathbf{x} \mid \theta)\)</span>, which can be read as <em>how likely it is that the data generated (by our model with parameters <span class="math inline">\(\theta\)</span>) comes from the training data</em>. If this quantity is high, it means that our generated images look very similar to the ground truth images in our training dataset, which is great—because it means that the generated images are realistic!</p>
<p>Therefore, our goal with these generative models will be (at least in part) to <strong>maximize the likelihood</strong> <span class="math inline">\(p(\mathbf{x} \mid \theta)\)</span> or, rather, its logarithm since it is more numerically stable: <span class="math inline">\(\log p(\mathbf{x} \mid \theta)\)</span>. However, this term is usually written as <span class="math inline">\(\log p_\theta(\mathbf{x})\)</span> to make it shorter. But keep in mind that both are exactly the same: <span class="math inline">\(p_\theta(\mathbf{x}) = p(\mathbf{x} \mid \theta)\)</span>.</p>
<p>Nevertheless, we came here to generate new images—not to only learn how to perfectly rebuild an already existing one. Therefore, we will add some additional terms to the loss function to encourage generative properties (instead of the pure reconstruction quality measured by the likelihood).</p>
<p>That’s why the VAE loss function includes an additional term: the Kullback-Leibler (KL) Divergence between the learned latent space <span class="math inline">\(Z\)</span> and a Standard Normal distribution <span class="math inline">\(\mathcal{N}(0, 1)\)</span> (which acts as a prior if we think in Bayes’ theorem terms). This allows the model to be a generative one: since the learned latent space <span class="math inline">\(Z\)</span> will closely resemble a Normal distribution, we can sample from that distribution to generate new, varied images! That’s why the VAE has those two terms in its loss function: the likelihood (also usually known as the <em>reconstruction term</em>) and the KL divergence (also usually known as the <em>prior matching term</em>).</p>
<p>The composition of these two terms gives us the VAE loss function to minimize, which is the maximization of a quantity usually known as <strong>ELBO</strong> (Evidence Lower BOund)—even though it is also known as VLB (Variational Lower Bound). We won’t discuss here why it is called this way or why it is usually expressed as an inequality <span class="math inline">\(\log p_\theta(\mathbf{x}) &gt;= \text{ELBO}\)</span> (to learn more about this we would need to explain how <em>variational inference</em> works in bayesian statistics, and trust me: it ain’t easy and we would easily deviate from the topic). After some development, we end up with the following definition for the VAE’s ELBO:</p>
<p><span class="math display">\[\text{ELBO}_\text{VAE} = \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}\mid \mathbf{x})}[\log p_\theta(\mathbf{x}\mid \mathbf{z})] - \mathcal{D}_{\text{KL}}(q_\phi(\mathbf{z} \mid \mathbf{x}) \mid \mid p(\mathbf{z}))\]</span></p>
<p>There is a lot to digest here. First and foremost, <span class="math inline">\(\mathbf{z}\)</span> is the random variable from the latent space <span class="math inline">\(Z\)</span>, and we will call <span class="math inline">\(\phi\)</span> to the autoencoder’s parameters/weights in the encoder, while we will leave <span class="math inline">\(\theta\)</span> to represent the parameters/weights for the decoder. Therefore:</p>
<ul>
<li><p><span class="math inline">\(\log p_\theta(\mathbf{x}\mid \mathbf{z})\)</span> is the (log) likelihood of the VAE’s decoder output (that generates images <span class="math inline">\(\mathbf{x}\)</span> given a sampled instance <span class="math inline">\(\mathbf{z}\)</span> from the latent space <span class="math inline">\(Z\)</span>), which measures how well the decoder is able to create images that look as if they came from the original data. Hence, this is the reconstruction term (don’t worry for now about the expectation <span class="math inline">\(\mathbb{E}\)</span>; it just means averaging over all possible values of <span class="math inline">\(\mathbf{z}\)</span>)</p></li>
<li><p><span class="math inline">\(\mathcal{D}_{\text{KL}}(q_\phi(\mathbf{z} \mid \mathbf{x}) \mid \mid p(\mathbf{z}))\)</span> is the Kullback-Leibler Divergence between the encoder’s output (the data in the latent space <span class="math inline">\(\mathbf{z}\)</span> given a training data image <span class="math inline">\(\mathbf{x}\)</span>) and <span class="math inline">\(p(\mathbf{z})\)</span>, which is the prior for the latent space <span class="math inline">\(Z\)</span>. We set this prior to a Standard Normal <span class="math inline">\(\mathcal{N}(0, 1)\)</span> in the VAE, as stated earlier. This divergence is always <span class="math inline">\(\geq0\)</span> (all KL divergences always are), and the lower the better (because that it would mean that the latent space <span class="math inline">\(Z\)</span> resembles a Standard Normal, from which we can easily sample). Therefore, this is the prior matching term</p></li>
</ul>
<p>So, to train a VAE we try to maximize the ELBO. In order to do so, we will maximize the reconstruction term and minimize the prior matching term at the same time.</p>
<p>That is the “final” expression for the VAE ELBO. However, to understand better DDPM’s ELBO it would be useful to use a more generic expression for VAE’s ELBO. To do so, we can work our way back. To do so, we can recall a general definition of KL divergence as:</p>
<p><span class="math display">\[\mathcal{D}_{\text{KL}}(q\mid \mid p) = \mathbb{E}_x \left[ \log \frac{q(x)}{p(x)} \right] \tag{7} \label{7}\]</span></p>
<p>Which can be used to “undo” the KL divergence in VAE loss as:</p>
<p><span class="math display">\[\begin{align}
\text{ELBO}_\text{VAE} &amp; = \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}\mid \mathbf{x})}[\log p_\theta(\mathbf{x}\mid \mathbf{z})] - \mathcal{D}_{\text{KL}}(q_\phi(\mathbf{z} \mid \mathbf{x}) \mid \mid p(\mathbf{z})) \\
\, \\
&amp;= \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}\mid \mathbf{x})}[\log p_\theta(\mathbf{x}\mid \mathbf{z})] - \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}\mid \mathbf{x})} \left[ \log \frac{q_\phi (\mathbf{z} \mid \mathbf{x})}{p(\mathbf{z})} \right] \\
\, \\
&amp; \text{given the property } \log \frac{a}{b} = - \log \frac{b}{a} \text{:} \\
&amp;= \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}\mid \mathbf{x})}[\log p_\theta(\mathbf{x}\mid \mathbf{z})] + \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}\mid \mathbf{x})} \left[ \log \frac{p(\mathbf{z})}{q_\phi (\mathbf{z} \mid \mathbf{x})} \right] \\
\, \\
&amp; \text{applying } \log a + \log b = \log(a \cdot b) \text{:} \\
&amp;= \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}\mid \mathbf{x})} \left[ \log \frac{p_\theta(\mathbf{x}\mid \mathbf{z}) \cdot p(\mathbf{z})}{q_\phi (\mathbf{z} \mid \mathbf{x})} \right] \\
\, \\
&amp; \text{with the product rule of joint probabilities } p(u, v) = p(u \mid v) \cdot p(v) \text{:} \\
&amp;= \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}\mid \mathbf{x})} \left[ \log \frac{p_\theta(\mathbf{x}, \mathbf{z})}{q_\phi (\mathbf{z} \mid \mathbf{x})} \right] \tag{8} \label{8}\\
\end{align}\]</span> <br> This is the expression we will start from in order to compute the ELBO for the DDPM model. <br><br></p>
</section>
<section id="b.2.-ddpm-loss" class="level2">
<h2 class="anchored" data-anchor-id="b.2.-ddpm-loss">B.2. DDPM loss</h2>
<p>To start working on the DDPM loss, we just have to adapt the ELBO we have for the VAE to suit the model differences between VAEs and DDPMs, as we discussed earlier. Therefore, we will introduce the following changes:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{z}\)</span> doesn’t really exist as a latent space in DDPMs. Or rather, we could say that in DDPMs we have <em>many latent spaces</em>—the image with each of the different noise levels!: <span class="math inline">\(\mathbf{x}_0, \mathbf{x}_1,\ldots,\mathbf{x}_T\)</span>. Therefore <span class="math inline">\(p_\theta(\mathbf{x}, \mathbf{z})\)</span> in <span class="math inline">\(\eqref{8}\)</span>, the joint distribution of <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{z}\)</span>, will become <span class="math inline">\(p_\theta(\mathbf{x}_{0 : T})\)</span> (the joint distribution over all different noise states for an image)</p></li>
<li><p><span class="math inline">\(q_\phi (\mathbf{z} \mid \mathbf{x})\)</span> was the encoder output in the VAE, but in DDPM it is the forward diffusion process. As we stated earlier, the forward process does not have any learnable parameters <span class="math inline">\(\phi\)</span> since it is not a learned process; therefore, we can fully drop <span class="math inline">\(\phi\)</span> from the notation. Furthermore, compared to a VAE now the goal is to produce noisy versions of the image <span class="math inline">\(\mathbf{x}_1, \mathbf{x}_2,\ldots,\mathbf{x}_T\)</span> starting from <span class="math inline">\(\mathbf{x}_0\)</span>. Hence, <span class="math inline">\(q_\phi (\mathbf{z} \mid \mathbf{x})\)</span> will now become <span class="math inline">\(q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)\)</span> for our DDPM.</p></li>
</ul>
<p>With this in mind, the ELBO for the DDPM model becomes:</p>
<p><span class="math display">\[\text{ELBO}_\text{DDPM} = \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p_\theta(\mathbf{x}_{0 : T})}{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \right] \tag{9} \label{9}\]</span> <br></p>
<p>As seen in Equation <span class="math inline">\((3)\)</span> of the DDPM paper. Now, to make this quantity manageable, let’s perform some derivations. We showed in slide 17 that the reverse process can be expressed as a chain of denoising steps from a fully noisy image <span class="math inline">\(p(\mathbf{x}_T)\)</span>—<span id="x_t">which is just data from a Standard Normal</span> <span class="math inline">\(\mathcal{N}(0, \mathbf{I})\)</span>—all the way back to the original image <span class="math inline">\(\mathbf{x}_0\)</span>. Using the <a href="https://en.wikipedia.org/wiki/Chain_rule_(probability)" target="_blank">chain rule of probability</a> and the Markov property, this can be expressed as:</p>
<p><span class="math display">\[p_{\theta}(\mathbf{x}_{0:T}) \coloneqq p(\mathbf{x}_T) \prod_{t=1}^T{p_{\theta}(\mathbf{x}_{t-1} \mid \mathbf{x}_{t})} \tag{10} \label{10}\]</span> <br> As seen in slide 17 and in Equation <span class="math inline">\((1)\)</span> of the DDPM paper. We can then develop the numerator in <span class="math inline">\(\eqref{9}\)</span> according to that logic: <span class="math display">\[\text{ELBO}_\text{DDPM} = \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) \prod_{t=1}^T{p_{\theta}(\mathbf{x}_{t-1} \mid \mathbf{x}_{t})}}{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \right] \tag{11} \label{11}\]</span> <br> Similarly, for the forward process we have a similar chain, in this case in the form of: <span class="math display">\[q(\mathbf{x}_{1:T} \mid \mathbf{x}_0) \coloneqq \prod^T_{t=1}{q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1})} \tag{12} \label{12}\]</span> <br> As seen in Equation <span class="math inline">\((2)\)</span> of the DDPM paper. This can be substituted in the denominator of <span class="math inline">\(\eqref{11}\)</span> to get:</p>
<p><span class="math display">\[\text{ELBO}_\text{DDPM} = \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) \prod_{t=1}^T{p_{\theta}(\mathbf{x}_{t-1} \mid \mathbf{x}_{t})}}{\prod^T_{t=1}{q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1})}} \right] \tag{13} \label{13}\]</span> <br> We will now slightly further develop the products, since it will become handy later. We will decouple the first term from the product in <span class="math inline">\(\eqref{10}\)</span>:</p>
<p><span class="math display">\[\prod_{t=1}^T{p_{\theta}(\mathbf{x}_{t-1} \mid \mathbf{x}_{t})} = p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1) \prod_{t=2}^T {p_{\theta}(\mathbf{x}_{t-1} \mid \mathbf{x}_{t})}\]</span> <br> And the same for <span class="math inline">\(\eqref{12}\)</span>:</p>
<p><span class="math display">\[\prod^T_{t=1}{q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1})} = q(\mathbf{x}_1 \mid \mathbf{x}_0) \prod^T_{t=2}{q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1})}\]</span> <br> Including these two back in <span class="math inline">\(\eqref{13}\)</span>:</p>
<p><span class="math display">\[\text{ELBO}_\text{DDPM} = \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1) \prod_{t=2}^T{p_{\theta}(\mathbf{x}_{t-1} \mid \mathbf{x}_{t})}}{q(\mathbf{x}_1 \mid \mathbf{x}_0) \prod^T_{t=2}{q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1})}} \right] \tag{14} \label{14}\]</span> <br> That <span class="math inline">\(q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1})\)</span> in the product in the denominator seems inoffensive. But trust me: after some more derivations, we will end up with a term in the ELBO in the form of <span class="math inline">\(\mathbb{E}_{q(\mathbf{x}_{t-1}, \mathbf{x}_{t+1} \mid \mathbf{x}_0)} \left[ \text{something} \right]\)</span>, which is an expectation over two random variables <span class="math inline">\(\mathbf{x}_{t-1}\)</span> and <span class="math inline">\(\mathbf{x}_{t+1}\)</span>. This can be approximated through Monte Carlo estimates, but it will yield high variance estimates and will be suboptimal.</p>
<p>Instead, we will be able to get rid of that ugly expectation by using a simple idea: we can instead re-write <span class="math inline">\(q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1})\)</span> as being conditioned on <span class="math inline">\(\mathbf{x}_0\)</span> (the original image), yielding <span class="math inline">\(q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}, \mathbf{x}_0)\)</span>. Due to the Markov property these two are exactly the same, so <span class="math inline">\(q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}, \mathbf{x}_0) = q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1})\)</span>. However, we will use the one conditioned on <span class="math inline">\(\mathbf{x}_0\)</span>, since in a moment we will expand that expression using Bayes’ theorem, which will allow us to avoid the expectation over two variables.</p>
<p>With that in mind, we will substitute that term in the denominator of <span class="math inline">\(\eqref{14}\)</span>:</p>
<p><span class="math display">\[\text{ELBO}_\text{DDPM} = \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1) \prod_{t=2}^T{p_{\theta}(\mathbf{x}_{t-1} \mid \mathbf{x}_{t})}}{q(\mathbf{x}_1 \mid \mathbf{x}_0) \prod^T_{t=2}{q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}, \mathbf{x}_0)}} \right]\]</span> <br> Now let’s take advantage of <span class="math inline">\(\log (a \cdot b) = \log a + \log b\)</span> and split the expression into two summands, isolating the products:</p>
<p><span class="math display">\[\text{ELBO}_\text{DDPM} = \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)}{q(\mathbf{x}_1 \mid \mathbf{x}_0)} + \log \prod^T_{t=2}{\frac{p_{\theta}(\mathbf{x}_{t-1} \mid \mathbf{x}_{t})}{q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}, \mathbf{x}_0)}} \right]\]</span> <br> We will now apply <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" target="_blank">Bayes’ theorem</a> to the denominator in the product, as we anticipated before:</p>
<p><span class="math display">\[\begin{align}
\text{ELBO}_\text{DDPM} &amp; = \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)}{q(\mathbf{x}_1 \mid \mathbf{x}_0)} + \log \prod^T_{t=2}{\frac{p_{\theta}(\mathbf{x}_{t-1} \mid \mathbf{x}_{t})}{\frac{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) q(\mathbf{x}_t \mid \mathbf{x_0})}{q(\mathbf{x}_{t-1} \mid \mathbf{x_0})}}} \right] \\
\, \\
&amp; \text{rearranging the denominator in the last term:} \\
&amp; = \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)}{q(\mathbf{x}_1 \mid \mathbf{x}_0)} + \log \left( \prod_{t=2}^{T}{\frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)}} \times \prod_{t=2}^{T}{\frac{q(\mathbf{x}_{t-1} \mid \mathbf{x}_0)}{q(\mathbf{x}_t \mid \mathbf{x}_0)}}  \right) \right] \tag{15} \label{15}
\end{align}\]</span> <br> And we can simplify the last product in <span class="math inline">\(\eqref{15}\)</span>. To see how, let’s develop it for instance assuming that <span class="math inline">\(T = 6\)</span>:</p>
<p><span class="math display">\[\begin{align}
\prod_{t=2}^{6}{\frac{q(\mathbf{x}_{t-1} \mid \mathbf{x}_0)}{q(\mathbf{x}_t \mid \mathbf{x}_0)}} &amp;= \frac{q(\mathbf{x}_1 \mid \mathbf{x}_0)}{q(\mathbf{x}_2 \mid \mathbf{x}_0)} \times \frac{q(\mathbf{x}_2 \mid \mathbf{x}_0)}{q(\mathbf{x}_3 \mid \mathbf{x}_0)} \times \frac{q(\mathbf{x}_3 \mid \mathbf{x}_0)}{q(\mathbf{x}_4 \mid \mathbf{x}_0)} \times \frac{q(\mathbf{x}_4 \mid \mathbf{x}_0)}{q(\mathbf{x}_5 \mid \mathbf{x}_0)} \times \frac{q(\mathbf{x}_5 \mid \mathbf{x}_0)}{q(\mathbf{x}_6 \mid \mathbf{x}_0)} \\
\, \\
&amp; \text{we can cancel out most terms, as are present in both numerator and denominator:} \\
&amp; = \frac{q(\mathbf{x}_1 \mid \mathbf{x}_0)}{\cancel{q(\mathbf{x}_2 \mid \mathbf{x}_0)}} \times \frac{\cancel{q(\mathbf{x}_2 \mid \mathbf{x}_0)}}{\cancel{q(\mathbf{x}_3 \mid \mathbf{x}_0)}} \times \frac{\cancel{q(\mathbf{x}_3 \mid \mathbf{x}_0)}}{\cancel{q(\mathbf{x}_4 \mid \mathbf{x}_0)}} \times \frac{\cancel{q(\mathbf{x}_4 \mid \mathbf{x}_0)}}{\cancel{q(\mathbf{x}_5 \mid \mathbf{x}_0)}} \times \frac{\cancel{q(\mathbf{x}_5 \mid \mathbf{x}_0)}}{q(\mathbf{x}_6 \mid \mathbf{x}_0)} \\
\, \\
&amp; = \frac{q(\mathbf{x}_1 \mid \mathbf{x}_0)}{q(\mathbf{x}_6 \mid \mathbf{x}_0)}
\end{align}\]</span> <br> You can see the clear pattern, right? Knowing this, <span class="math inline">\(\eqref{15}\)</span> becomes:</p>
<p><span class="math display">\[\begin{align}
\text{ELBO}_\text{DDPM} &amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)}{q(\mathbf{x}_1 \mid \mathbf{x}_0)} + \log \left( \prod_{t=2}^{T}{\frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)}} \times \frac{q(\mathbf{x}_1 \mid \mathbf{x}_0)}{q(\mathbf{x}_T \mid \mathbf{x}_0)} \right) \right] \\
\, \\
&amp; \text{applying } \log(a \cdot b) = \log a + \log b \text{:} \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)}{q(\mathbf{x}_1 \mid \mathbf{x}_0)} + \log \frac{q(\mathbf{x}_1 \mid \mathbf{x}_0)}{q(\mathbf{x}_T \mid \mathbf{x}_0)} + \log  \prod_{t=2}^{T}{\frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)}} \right] \\
\, \\
&amp; \text{now applying } \log a + \log b = \log(a \cdot b) \text{:} \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \left( \frac{p(\mathbf{x}_T) p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)}{q(\mathbf{x}_1 \mid \mathbf{x}_0)} \times \frac{q(\mathbf{x}_1 \mid \mathbf{x}_0)}{q(\mathbf{x}_T \mid \mathbf{x}_0)} \right) + \log  \prod_{t=2}^{T}{\frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)}} \right] \\
\, \\
&amp; \text{cancelling out:} \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \left( \frac{p(\mathbf{x}_T) p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)}{\cancel{q(\mathbf{x}_1 \mid \mathbf{x}_0)}} \times \frac{\cancel{q(\mathbf{x}_1 \mid \mathbf{x}_0)}}{q(\mathbf{x}_T \mid \mathbf{x}_0)} \right) + \log  \prod_{t=2}^{T}{\frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)}} \right] \\
\, \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)}{q(\mathbf{x}_T \mid \mathbf{x}_0)} + \log  \prod_{t=2}^{T}{\frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)}} \right] \\
\, \\
&amp; \text{splitting the first log (again: } \log(a \cdot b) = \log a + \log b \text{):} \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1) + \log \frac{p(\mathbf{x}_T)}{q(\mathbf{x}_T \mid \mathbf{x}_0)} + \log  \prod_{t=2}^{T}{\frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)}} \right] \\
\, \\
&amp; \text{applying yet again} \log(a \cdot b) = \log a + \log b \text{, but now to the product in the third term:} \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1) + \log \frac{p(\mathbf{x}_T)}{q(\mathbf{x}_T \mid \mathbf{x}_0)} + \sum_{t=2}^{T}{\log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)}} \right] \\
\, \\
&amp; \text{due to the linearity of expectation property: } \mathbb{E}[X + Y] = \mathbb{E}[X] + \mathbb{E}[Y] \text{:} \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1) \right] + \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T)}{q(\mathbf{x}_T \mid \mathbf{x}_0)} \right] + \sum_{t=2}^{T}{ \mathbb{E}_{q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)} \left[ \log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)} \right]} \tag{16} \label{16}\\
\end{align}\]</span> <br></p>
<p>With this, we end up with three expectation terms. All three are expectations over <span class="math inline">\(q(\mathbf{x}_{1:T}\mid \mathbf{x}_0)\)</span>. However, it doesn’t make sense to try to compute the expectation (which is nothing but a weighted average) over terms that do not appear inside the brackets of that specific expectation. For instance, within the brackets of the first expectation we only have <span class="math inline">\(\mathbf{x}_0\)</span> and <span class="math inline">\(\mathbf{x}_1\)</span>, so any other <span class="math inline">\(\mathbf{x}_\ldots\)</span> which is present in <span class="math inline">\(1:T\)</span> can be dropped from the subscript.</p>
<p>Therefore, we can write <span class="math inline">\(\eqref{16}\)</span> as:</p>
<p><span class="math display">\[\text{ELBO}_\text{DDPM} = \mathbb{E}_{q(\mathbf{x}_{1} \mid \mathbf{x}_0)} \left[ \log p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1) \right] + \mathbb{E}_{q(\mathbf{x}_{T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T)}{q(\mathbf{x}_T \mid \mathbf{x}_0)} \right] + \sum_{t=2}^{T}{ \mathbb{E}_{q(\mathbf{x}_{t}, \mathbf{x}_{t-1} \mid \mathbf{x}_0)} \left[ \log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)} \right]} \tag{17} \label{17}\]</span> <br> Now, the second and third terms look very similar to KL Divergences. We can therefore apply <span class="math inline">\(\eqref{7}\)</span> in reverse to get KL Divergences from the expectations. For the second term, it is quite straightforward. Knowing that <span class="math inline">\(\log \frac{a}{b} = - \log \frac{b}{a}\)</span>:</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}_{q(\mathbf{x}_{T} \mid \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T)}{q(\mathbf{x}_T \mid \mathbf{x}_0)} \right] &amp; = - \mathbb{E}_{q(\mathbf{x}_{T} \mid \mathbf{x}_0)} \left[ \log \frac{q(\mathbf{x}_T \mid \mathbf{x}_0)}{p(\mathbf{x}_T)} \right] \\
\, \\
&amp; = - \mathcal{D}_{\text{KL}}(q(\mathbf{x}_T \mid \mathbf{x}_0) \mid \mid p(\mathbf{x}_T)) \tag{18} \label{18}
\end{align}\]</span> <br> As for the third term in <span class="math inline">\(\eqref{17}\)</span>, the expectation is over <span class="math inline">\(q(\mathbf{x}_t, \mathbf{x}_{t-1} \mid \mathbf{x}_0)\)</span>. This one is a bit trickier, but we can deal with it nevertheless.</p>
<p>To better understand how it works, we will convert the expectation to an integral. This can be done by using what is known as the <a href="https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician"><em>Law of the unconscious statistician</em></a> or <em>LOTUS</em> (yes: that is the actual name). The LOTUS is as follows:</p>
<p><span class="math display">\[\mathbb{E}_x [f(x, y)] = \int{\text{pdf}(x) \cdot f(x, y)\,\, dx}\]</span></p>
<p>Where:</p>
<ul>
<li><p><span class="math inline">\(f(x, y)\)</span> is any function involving two random variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> (similar to the <span class="math inline">\(\log\)</span> we have above)</p></li>
<li><p><span class="math inline">\(\text{pdf}(x)\)</span> is the pdf (<a href="https://en.wikipedia.org/wiki/Probability_density_function" target="_blank">probability density function</a>) of <span class="math inline">\(x\)</span></p></li>
</ul>
<p>So we are integrating over <span class="math inline">\(x\)</span> (hence the <span class="math inline">\(dx\)</span> at the end); this is because that is the subscript in the expectation.</p>
<p>Let’s apply this law to that third expectation term in <span class="math inline">\(\eqref{17}\)</span>. In our case, we have a joint probability in our expectation. Therefore, we will write the integral as follows:</p>
<p><span class="math display">\[\mathbb{E}_{q(\mathbf{x}_{t}, \mathbf{x}_{t-1} \mid \mathbf{x}_0)} \left[ \log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)} \right] = \int{\int{q(\mathbf{x}_{t}, \mathbf{x}_{t-1} \mid \mathbf{x}_0) \cdot \log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)}}} \,\, d\mathbf{x}_{t-1} d\mathbf{x}_{t}\]</span> <br> Given that we integrate over both <span class="math inline">\(\mathbf{x}_{t-1}\)</span> and <span class="math inline">\(\mathbf{x}_{t}\)</span>, we have a double integral.</p>
<p>Now, the expression <span class="math inline">\(q(\mathbf{x}_{t}, \mathbf{x}_{t-1} \mid \mathbf{x}_0)\)</span> can be split into two using the chain rule of probability as follows:</p>
<p><span class="math display">\[q(\mathbf{x}_{t}, \mathbf{x}_{t-1} \mid \mathbf{x}_0) = q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \cdot q(\mathbf{x}_t \mid \mathbf{x}_0)
\]</span> <br> Substituting this in the integrals:</p>
<p><span class="math display">\[\begin{align}
&amp; \int{\int{q(\mathbf{x}_{t}, \mathbf{x}_{t-1} \mid \mathbf{x}_0) \cdot \log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)}}} \,\, d\mathbf{x}_{t-1} d\mathbf{x}_{t} \\
\, \\
&amp; = \int{\int{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \cdot q(\mathbf{x}_t \mid \mathbf{x}_0) \cdot \log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)}}} \,\, d\mathbf{x}_{t-1} d\mathbf{x}_{t} \\
\, \\
&amp; \text{add parentheses to make notation easier to read:} \\
&amp; = \int{ \left( \int{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \cdot q(\mathbf{x}_t \mid \mathbf{x}_0) \cdot \log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)}} \,\, d\mathbf{x}_{t-1} \right) } d\mathbf{x}_{t}
\end{align}\]</span> <br> Now to the main trick: the “inner” integral is integrating over <span class="math inline">\(\mathbf{x}_{t-1}\)</span>. And the term <span class="math inline">\(q(\mathbf{x}_t \mid \mathbf{x}_0)\)</span> does not include <span class="math inline">\(\mathbf{x}_{t-1}\)</span> at all (therefore it does not depend on it). This means that for the purposes of that inner integral, <span class="math inline">\(q(\mathbf{x}_t \mid \mathbf{x}_0)\)</span> is just a constant, and a multiplying constant can be taken out of the integral as follows:</p>
<p><span class="math display">\[\begin{align}
&amp; \int{ \left( \int{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \cdot q(\mathbf{x}_t \mid \mathbf{x}_0) \cdot \log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)}} \,\, d\mathbf{x}_{t-1} \right) } d\mathbf{x}_{t} \\
\, \\
&amp; = \int{ q(\mathbf{x}_t \mid \mathbf{x}_0) \cdot \left( \int{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \cdot \log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)}} \,\, d\mathbf{x}_{t-1} \right) } d\mathbf{x}_{t}
\end{align}\]</span> <br> With this, we can go back to writing expectations instead of integrals:</p>
<p><span class="math display">\[\begin{align}
&amp; \int{ q(\mathbf{x}_t \mid \mathbf{x}_0) \cdot \left( \int{q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \cdot \log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)}} \,\, d\mathbf{x}_{t-1} \right) } d\mathbf{x}_{t} \\
\, \\
&amp; = \mathbb{E}_{q(\mathbf{x}_t \mid \mathbf{x}_0)} \left[ \mathbb{E}_{q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)} \left[ \log  \frac{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)}{q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)} \right] \right] \\
\, \\
&amp; \text{knowing that } \log \frac{a}{b} = - \log \frac{b}{a}: \\
&amp; = - \mathbb{E}_{q(\mathbf{x}_t \mid \mathbf{x}_0)} \left[ \mathbb{E}_{q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)} \left[ \log  \frac{q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)} \right] \right]
\end{align}\]</span> <br></p>
<p>We can now use again the definition of KL divergence in <span class="math inline">\(\eqref{7}\)</span> to convert the inner expectation into a KL divergence:</p>
<p><span class="math display">\[\begin{align}
&amp; - \mathbb{E}_{q(\mathbf{x}_t \mid \mathbf{x}_0)} \left[ \mathbb{E}_{q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)} \left[ \log  \frac{q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)} \right] \right] \\
\, \\
&amp; = - \mathbb{E}_{q(\mathbf{x}_t \mid \mathbf{x}_0)} \left[ \mathcal{D}_{\text{KL}}(q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0) \mid \mid p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)) \right] \tag{19} \label{19}
\end{align}\]</span> <br> This way the third expectation is also greatly simplified.</p>
<p>With that, we can now plug <span class="math inline">\(\eqref{18}\)</span> and <span class="math inline">\(\eqref{19}\)</span> back into the ELBO in <span class="math inline">\(\eqref{17}\)</span>:</p>
<p><span class="math display">\[\text{ELBO}_\text{DDPM} = \mathbb{E}_{q(\mathbf{x}_{1} \mid \mathbf{x}_0)} \left[ \log p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1) \right] - \mathcal{D}_{\text{KL}}(q(\mathbf{x}_T \mid \mathbf{x}_0) \mid \mid p(\mathbf{x}_T)) - \sum_{t=2}^{T}{\mathbb{E}_{q(\mathbf{x}_t \mid \mathbf{x}_0)} \left[ \mathcal{D}_{\text{KL}}(q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0) \mid \mid p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)) \right]}\]</span> <br> And that’s the loss function for the DDPM model! Let’s label each of these three terms:</p>
<p><span class="math display">\[\text{ELBO}_\text{DDPM} = \underbrace{\mathbb{E}_{ q(\mathbf{x}_{1} \mid \mathbf{x}_0)} \left[ \log p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1) \right]}_{\text{reconstruction term}} - \underbrace{ \mathcal{D}_{\text{KL}}(q(\mathbf{x}_T \mid \mathbf{x}_0) \mid \mid p(\mathbf{x}_T))}_{\text{prior matching term}} - \sum_{t=2}^{T}{\underbrace{ \mathbb{E}_{q(\mathbf{x}_t \mid \mathbf{x}_0)} \left[ \mathcal{D}_{\text{KL}}(q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0) \mid \mid p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)) \right]}_{\text{denoising matching term}}} \tag{20} \label{20}\]</span></p>
<p>We can briefly describe these three:</p>
<ul>
<li><p>The reconstruction term is very similar to the VAE one, with the difference that since in the DDPM model we have many denoising steps in the reverse diffusion process, this term only focuses on the last step: Going from <span class="math inline">\(\mathbf{x}_{1}\)</span> to <span class="math inline">\(\mathbf{x}_0\)</span>, this is: from the least noisy image to the original one</p></li>
<li><p>The prior matching term represents how close the most noisy image is to <span class="math inline">\(p(\mathbf{x}_T)\)</span>, which if you remember, <a href="#x_t">we said</a> that this is just full noise data from a Standard Normal <span class="math inline">\(\mathcal{N}(0, \mathbf{I})\)</span>. Since there are no learnable weights/parameters in this term (no <span class="math inline">\(\theta\)</span> involved anywhere), we can safely ignore it during training</p></li>
<li><p>The <em>denoising matching term</em> is the bulk of our loss. It tries to make our model’s learned reverse diffusion process <span class="math inline">\(p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\)</span> as close as possible to what would be the ground-truth, real reverse diffusion process, as represented by <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0)\)</span>. We will call this ground-truth the <em>forward process posterior</em> and will be described in detail in <a href="#c.-the-forward-process-posterior">Appendix C</a> <br></p></li>
</ul>
<p>To make sure we understand, let’s take a look at the diagram in slide 18:</p>
<p><img src="images/ddpm_process_and_equations.png" class="img-fluid"></p>
<p>The bulk of our loss is the denoising matching term, which is the KL divergence between what would be the perfect reverse diffusion process (called <em>forward process posterior</em>) and the one that our model will produce. This means that if our model is able to closely replicate this forward process posterior, we will end up with great quality images! That is why this will be the focus of our procedure. <br><br></p>
<p>Sidenote: If you look at the DDPM paper, you will find a similar yet different formula in Equation <span class="math inline">\((5)\)</span> of the DDPM paper. Let’s write it down here:</p>
<p><span class="math display">\[- \text{ELBO}_\text{DDPM} = \mathbb{E}_q \left[ \underbrace {\mathcal{D}_{\text{KL}}(q(\mathbf{x}_T \mid \mathbf{x}_0) \mid \mid p(\mathbf{x}_T))}_{L_T} + \sum_{t=2}^T{\underbrace{\mathcal{D}_{\text{KL}}(q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \mid \mid p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t))}_{L_{t-1}}} \underbrace{ - \log p_\theta(\mathbf{x}_0 \mid \mathbf{x}_1)}_{L_0} \right] \tag{21} \label{21}\]</span> <br> It is actually the same equation as <span class="math inline">\(\eqref{20}\)</span> which we just developed, but with three differences:</p>
<ul>
<li><p>The one in the paper is the negative ELBO (therefore it will be minimized instead of maximized), so signs have flipped</p></li>
<li><p>They change the order of the terms, which obviously does not affect at all</p></li>
<li><p>The paper’s notation is more vague when it comes to expressing the expectation. However, it is not important. When training the model, the common way to minimize an expectation is basically through iterating over training samples with stochastic gradient descent many times. Therefore, in the paper they do some abuse of notation and just write a single expectation with a generic subscript <span class="math inline">\(q\)</span></p></li>
</ul>
<p>Other than that, it is the exact same formula. So, from now on we will use this equation for the loss.</p>
<p>In the paper they refer to those three terms with the names <span class="math inline">\(L_T\)</span>, <span class="math inline">\(L_{t-1}\)</span> and <span class="math inline">\(L_0\)</span> (instead of prior matching, denoising matching and reconstruction, respectively):</p>
<ul>
<li><p><span class="math inline">\(L_T\)</span>, as stated before, has no learnable parameters: so we don’t care about it and we will just drop it</p></li>
<li><p><span class="math inline">\(L_{t-1}\)</span> will be our focus</p></li>
<li><p><span class="math inline">\(L_0\)</span> gets a special treatment in Section 3.3 of the DDPM paper, and they show how it can be learned with a separate model. However, it just focuses on what would be the very last denoising step (out of a thousand of them); therefore, its importance is quite negligible (as <span class="math inline">\(\mathbf{x}_{1}\)</span> is almost noiseless already, given that we have set a small enough <span class="math inline">\(\beta_t\)</span>). Therefore, the authors decide in Section 3.4 to ignore this term as well<br><br></p></li>
</ul>
<p><em>Note: This same derivation can be found in Appendix A (page 13) of the DDPM paper. However, the steps described here go into much more detail than what you will find there. With that said, it is basically the same derivation.</em><br><br></p>
<p>To conclude: all of a sudden, our model will only care about <span class="math inline">\(L_{t-1}\)</span>. We will build the model training procedure out of this term. <br><br></p>
<hr>
</section>
</section>
<section id="c.-the-forward-process-posterior" class="level1">
<h1>C. The <em>forward process posterior</em></h1>
<p>In <a href="#b.-diffusion-loss-function-elbo-derivation">Appendix B</a> we concluded that we will focus on the <span class="math inline">\(L_{t-1}\)</span> component of the ELBO:</p>
<p><span class="math display">\[ \mathcal{D}_{\text{KL}} (q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \mid\mid p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t))\]</span></p>
<p>If we look closely, we can see that the second term <span class="math inline">\(p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\)</span> is what we will predict with our model: a single step of the reverse diffusion process (as we described in slide 17).</p>
<p>However, the first term <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)\)</span> in that KL divergence is not that clear. Since we have <span class="math inline">\(q\)</span> in there, it looks like it is the forward diffusion process; but in a way that we try to apply the forward process <em>the other way around</em>, trying to go to a less noisy image <span class="math inline">\(\mathbf{x}_{t-1}\)</span> from a noisier one <span class="math inline">\(\mathbf{x}_t\)</span>. So it looks more like the reverse process, but based on <span class="math inline">\(q\)</span>. <br><br></p>
<p>Indeed, this is known as the <em>forward process posterior</em>. Let’s forget for a second about the <span class="math inline">\(\mathbf{x}_0\)</span> in the term, and look only at <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\)</span>. The easiest way to think of it is like a version of the reverse diffusion process, but in which we don’t need to use a model to learn any parameters/weights. Rather, it is basically what would be the perfect, ground-truth reverse process, which just unapplies the noise in the same fashion as how it was applied during the forward process. However, if computing analytically (this is, without approximations) <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\)</span> was possible, we would not need a diffusion model at all! We could just undo the forward diffusion process applying that through multiple steps, and we would get back the perfect, noiseless image out of pure gaussian noise. <br><br></p>
<p>Unfortunately, this forward process posterior <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\)</span> is intractable to compute in real life. Without going into much detail, it is kind of intuitive: if I gave you some very noisy image and nothing else, would you be able to slightly denoise it to make it look closer to the original, noiseless image it came from? Most likely not. Trying to develop it using Bayes’ theorem does not help, as we would need to compute <span class="math inline">\(q(\mathbf{x}_t)\)</span>, which is the marginal distribution of images at step <span class="math inline">\(t\)</span>, and to compute this we would need to integrate over all possible values of <span class="math inline">\(\mathbf{x}_{t-1}\)</span>, which is also intractable. <br><br></p>
<p>To solve this problem, we can condition the forward process posterior on <span class="math inline">\(\mathbf{x}_0\)</span> (the original image) and use <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)\)</span>, and then we will be able to analytically compute this forward process posterior (as we will do below). To understand why, we can go again through the analogy: if I gave you some very noisy noise but now also the original, noiseless image, would you be able to slightly denoise the noisy image? Perhaps, right? Well: that is what we will do by conditioning on <span class="math inline">\(\mathbf{x}_0\)</span>. <br><br></p>
<p>Now we can continue. The forward process posterior <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t})\)</span> is tractable if:</p>
<ol type="1">
<li>We condition it on <span class="math inline">\(\mathbf{x}_0\)</span>—therefore turning it into <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)\)</span> (as just discussed), and</li>
<li>We assume it is also a Normal distribution</li>
</ol>
<p>To better understand why we can assume it is a Normal distribution, the paper mentions in page 2 that <em>both processes</em> (meaning forward and backward) <em>have the same functional form when <span class="math inline">\(\beta_t\)</span> are small</em>, meaning that if the forward process is made of Normals, the reverse can also be (and the forward process posterior we are discussing is basically a non-learned reverse diffusion process); and they cite <a href="https://arxiv.org/abs/1503.03585" target="_blank">Sohl-Dickstein et al.&nbsp;[2015]</a> (in fact, this paper is the main inspiration for the DDPM paper), which in turn cites in page 5 <a href="https://www.semanticscholar.org/paper/On-the-Theory-of-Stochastic-Processes%2C-with-to-Feller/4cdcf495232f3ec44183dc74cd8eca4b44c2de64" target="_blank">Feller [1949]</a> as for why. <br><br></p>
<p>Given that we indeed set <span class="math inline">\(\beta_t\)</span> to be small, we can then assume that this forward process posterior is a Normal distribution as well. Given that it is a Normal distribution and that we are conditioning it on <span class="math inline">\(\mathbf{x}_0\)</span>, now the forward process posterior is a tractable distribution, as we will develop just now. Here it is:</p>
<p><span class="math display">\[q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0}) = \mathcal{N}(\mathbf{x}_{t-1};{\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})},{\color{red}\tilde{\beta}_t \mathbf{I}}) \tag{22} \label{22}\]</span> <br> As seen in Equation <span class="math inline">\((6)\)</span> of the DDPM paper. Note the tildes in the notation, meaning that these are new concepts that we have not seen before (and therefore we will need to derive). We have colored the mean and variance of this distribution, and we will now analytically compute what those two terms should be.</p>
<p>Applying Bayes’ rule, we will get:</p>
<p><span class="math display">\[q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0}) = {\color{#ba861a} q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1},\mathbf{x}_{0})} \frac{{\color{#20c8d2}q(\mathbf{x}_{t-1} \mid \mathbf{x}_{0})}}{{\color{#cb2783}q(\mathbf{x}_{t} \mid \mathbf{x}_{0})}} \tag{23} \label{23} \]</span> <br></p>
<p>We have colored each term separately to recognize them below. Under the assumption that all of those are Normal distributions, we can recall that the <a href="https://en.wikipedia.org/wiki/Normal_distribution" target="_blank">probability density function (pdf) of a Normal distribution</a> <span class="math inline">\(\mathcal{N}(\mu, \sigma^2)\)</span> is given by:</p>
<p><span class="math display">\[\text{pdf}(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</span> <br> To make it cleaner, let’s rewrite <span class="math inline">\(e^{\cdots}\)</span> as <span class="math inline">\(\exp(\cdots)\)</span>. Also, <span class="math inline">\(\frac{1}{\sqrt{2\pi\sigma^2}}\)</span> can be thought of as <em>some value</em>, and we won’t need it directly. Therefore, instead of an equality (<span class="math inline">\(=\)</span>) symbol, we can omit this term and use a <em>proportional to</em> (<span class="math inline">\(\propto\)</span>) symbol:</p>
<p><span class="math display">\[\begin{align}
\text{pdf}(x)
&amp;\propto \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right) \\
\, \\
&amp;=\exp\left(-\frac{1}{2} \cdot \frac{(x-\mu)^2}{\sigma^2}\right) \tag{24} \label{24}
\end{align}\]</span> <br></p>
<p>And now let’s develop each term in <span class="math inline">\(\eqref{23}\)</span> using the pdf. Let’s start with the first one: <span class="math inline">\({\color{#ba861a} q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1},\mathbf{x}_{0})}\)</span>. For that, we have to remember that due to the Markov property that rules the forward diffusion process:</p>
<p><span class="math display">\[{\color{#ba861a}q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1},\mathbf{x}_{0})} = q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1})\]</span> <br> And we already know that <span class="math inline">\(q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t\mathbf{I})\)</span> (as it is the standard forward diffusion process formula), so we know that the mean is <span class="math inline">\(\sqrt{1 - \beta_t}\)</span> and that the variance is <span class="math inline">\(\beta_t\)</span>. Therefore, we can express <span class="math inline">\({\color{#ba861a}q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1},\mathbf{x}_{0})}\)</span> in terms of its pdf as such:</p>
<p><span class="math display">\[\begin{align}
{\color{#ba861a}q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1},\mathbf{x}_{0})} &amp; \propto \exp\left( -\frac{1}{2} \cdot \frac{(\mathbf{x}_t - \sqrt{1 - \beta_t} \mathbf{x}_{t-1})^2}{\beta_t}\right) \\
\, \\
&amp; \text{since we defined } \alpha_t = 1-\beta_t: \\
&amp;=  \exp\left( -\frac{1}{2} \cdot {\color{#ba861a}\frac{(\mathbf{x}_t - \sqrt{\alpha_t} \mathbf{x}_{t-1})^2}{\beta_t}}\right)
\end{align}\]</span> <br> Where we have colored a specific (the most relevant) part of the pdf (the one that won’t be the same in the other two Bayes’ terms). <br></p>
<p>Second Bayes term in <span class="math inline">\(\eqref{23}\)</span>: <span class="math inline">\({\color{#20c8d2}q(\mathbf{x}_{t-1} \mid \mathbf{x}_{0})}\)</span>. Following the same pdf formula, we can clearly see that due to the Nice™ property <span class="math inline">\(\eqref{6}\)</span> we already know that this is just <span class="math inline">\(\mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0, (1 - \bar{\alpha}_{t-1}) \mathbf{I})\)</span>. Therefore, we also know the mean and variance, and we can also apply the pdf formula:</p>
<p><span class="math display">\[{\color{#20c8d2}q(\mathbf{x}_{t-1} \mid \mathbf{x}_{0})} \propto \exp\left( -\frac{1}{2} \cdot {\color{#20c8d2}\frac{(\mathbf{x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0})^2}{1 - \bar{\alpha}_{t-1}}}\right)\]</span> <br></p>
<p>And finally, for the last Bayes term in <span class="math inline">\(\eqref{23}\)</span>: <span class="math inline">\({\color{#cb2783}q(\mathbf{x}_{t} \mid \mathbf{x}_{0})}\)</span> we can also apply the Nice™ property analogously to the previous step and do:</p>
<p><span class="math display">\[{\color{#cb2783}q(\mathbf{x}_{t} \mid \mathbf{x}_{0})} \propto \exp\left( -\frac{1}{2} \cdot {\color{#cb2783}\frac{(\mathbf{x}_{t} - \sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0})^2}{1 - \bar{\alpha}_{t}}}\right)\]</span> <br></p>
<p>With all three terms developed, we can take advantage of the property <span class="math inline">\(e^a \cdot e^b = e^{a+b}\)</span> (and <span class="math inline">\(e^a / e^b = e^{a-b}\)</span>) and write the full forward process posterior in <span class="math inline">\(\eqref{22}\)</span> as:</p>
<p><span class="math display">\[\begin{align}
&amp; q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0}) \\
\, \\
&amp; = {\color{#ba861a} q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1},\mathbf{x}_{0})} \frac{{\color{#20c8d2}q(\mathbf{x}_{t-1} \mid \mathbf{x}_{0})}}{{\color{#cb2783}q(\mathbf{x}_{t} \mid \mathbf{x}_{0})}} \\
\, \\
&amp; \propto \exp \left(-\frac{1}{2} \cdot \Big({\color{#ba861a}\frac{(\mathbf{x}_t - \sqrt{\alpha_t} \mathbf{x}_{t-1})^2}{\beta_t}} + {\color{#20c8d2}\frac{(\mathbf{x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0})^2}{1 - \bar{\alpha}_{t-1}}} -{\color{#cb2783}\frac{(\mathbf{x}_{t} - \sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0})^2}{1 - \bar{\alpha}_{t}}}\Big) \right) \\
&amp; \, \\
&amp; \text{resetting colors:} \\
&amp; = \exp \left(-\frac{1}{2} \cdot \Big({\frac{(\mathbf{x}_t - \sqrt{\alpha_t} \mathbf{x}_{t-1})^2}{\beta_t}} + {\frac{(\mathbf{x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0})^2}{1 - \bar{\alpha}_{t-1}}} - {\frac{(\mathbf{x}_{t} - \sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0})^2}{1 - \bar{\alpha}_{t}}}\Big) \right) \\
&amp; \, \\
&amp; \text{developing first two squares:} \\
&amp; = \exp \left(-\frac{1}{2} \cdot \Big(\frac{\mathbf{x}^2_t + \alpha_t\mathbf{x}^2_{t-1}-2\mathbf{x}_t\sqrt{\alpha_t}\mathbf{x}_{t-1}}{\beta_t} + \frac{\mathbf{x}^2_{t-1} + \bar\alpha_{t-1}\mathbf{x}^2_0 - 2\mathbf{x}_{t-1}\sqrt{\bar\alpha_{t-1}}\mathbf{x}_0}{1 - \bar\alpha_{t-1}} - {\frac{(\mathbf{x}_{t} - \sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0})^2}{1 - \bar{\alpha}_{t}}}\Big) \right) \\
&amp; \, \\
&amp; \text{coloring :} \\
&amp; \quad \bullet \,\,{\color{#004ce9}\mathbf{x}_{t-1}} \text{ and everything that multiplies it in in {\color{#004ce9}blue}, and } \\
&amp; \quad \bullet \,\,{\color{red}\mathbf{x}^2_{t-1}} \text{ and everything that multiplies it in {\color{red}red}, and} \\
&amp; \quad \bullet \,\,\text{everything that divides both in {\color{#7f0f8f}purple}, and}\\
&amp; \quad \bullet \,\,\text{everything else (except for the }\exp \text{ and the }-\frac{1}{2}\text{) in {\color{#b9b9b9}gray}}:\\
&amp; = \exp \left(-\frac{1}{2} \cdot \Big(\frac{{\color{#b9b9b9}\mathbf{x}^2_t} + {\color{red}\alpha_t\mathbf{x}^2_{t-1}}{\color{#004ce9}-2\mathbf{x}_t\sqrt{\alpha_t}\mathbf{x}_{t-1}}}{{\color{#7f0f8f}\beta_t}} + \frac{{\color{red}\mathbf{x}^2_{t-1}} + {\color{#b9b9b9}\bar\alpha_{t-1}\mathbf{x}^2_0} {\color{#004ce9}- 2\mathbf{x}_{t-1}\sqrt{\bar\alpha_{t-1}}\mathbf{x}_0}}{{\color{#7f0f8f}1 - \bar\alpha_{t-1}}} - {\color{#b9b9b9} {\frac{(\mathbf{x}_{t} - \sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0})^2}{1 - \bar{\alpha}_{t}}}}\Big) \right) \\
&amp; \, \\
&amp; \text{re-arranging:} \\
&amp; = \exp \left(-\frac{1}{2} \cdot \Big( {\color{#004ce9}-2 \big(\frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{\sqrt{\bar\alpha_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_0 \big) \mathbf{x}_{t-1}} + {\color{red} \big( \frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar\alpha_{t-1}}\big)\mathbf{x}^2_{t-1}} + {\color{#b9b9b9}C(\mathbf{x}_t, \mathbf{x}_0)}\Big) \right) \tag{25} \label{25}
\end{align}\]</span> <br></p>
<p>Now we need to grab that huge expression and somehow “re-pack” it into something that also looks like a Normal distribution. In fact, all of that is proportional to the pdf to <em>some</em> Normal distribution (we say it is proportional due to the <span class="math inline">\(\propto\)</span> symbol). We just have to algebraically extract the parameters for such Normal.</p>
<p>You may be wondering about the <span class="math inline">\({\color{#b9b9b9}C(\mathbf{x}_t, \mathbf{x}_0)}\)</span> term. This is some function that uses all the gray terms in the equation above its appearance, but actually it does not depend on <span class="math inline">\(\mathbf{x}_{t-1}\)</span> at all. Since we are developing the pdf for <span class="math inline">\(q(\mathbf{x}_{t-1}\mid\mathbf{x}_t,\mathbf{x}_0)\)</span>, in reality we only care about what depends on <span class="math inline">\(\mathbf{x}_{t-1}\)</span>, and we can think of the rest as constants. Given that we are working with probability distributions, any constant can be thought of something that will end up normalizing the pdf so it integrates to 1 (the pdf of any probability distribution does). Therefore, we don’t really need to care about <span class="math inline">\({\color{#b9b9b9}C(\mathbf{x}_t, \mathbf{x}_0)}\)</span>: we can just assume that it is there, helping our quantity be a true pdf that integrates to 1. Hence, we will just remove the term from our equation.</p>
<p>Even more: given that <span class="math inline">\(\eqref{25}\)</span> is already something proportional to <span class="math inline">\(q(\mathbf{x}_{t-1}\mid\mathbf{x}_t,\mathbf{x}_0)\)</span>’s pdf, we can also keep saying the same and fully omit <span class="math inline">\({\color{#b9b9b9}C(\mathbf{x}_t, \mathbf{x}_0)}\)</span>, yielding:</p>
<p><span class="math display">\[q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0}) \propto \exp \left(-\frac{1}{2} \cdot \Big( {\color{#004ce9}-2 \big(\frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{\sqrt{\bar\alpha_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_0 \big) \mathbf{x}_{t-1}} + {\color{red} \big( \frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar\alpha_{t-1}}\big)\mathbf{x}^2_{t-1}}\Big) \right) \tag{26} \label{26}\]</span> <br></p>
<p>Now, let’s look again at the pdf formula for a Normal distribution <span class="math inline">\(\eqref{24}\)</span>:</p>
<p><span class="math display">\[\text{pdf}(x) \propto \exp\left(-\frac{1}{2} \cdot \frac{(x-\mu)^2}{\sigma^2}\right)\]</span> <br> It looks kind of similar to our <span class="math inline">\(\eqref{26}\)</span>, right?</p>
<p>It does. In fact: if we are able to make them match, we will be able to obtain the mean and variance of a Normal distribution whose pdf would be proportional to our red and blue expression. Being proportional would be enough, as we will perform optimization with it (a constant does not alter the optimization result).</p>
<p>Let’s develop the square on the pdf formula in <span class="math inline">\(\eqref{24}\)</span> a bit further:</p>
<p><span class="math display">\[\begin{align}
\text{pdf}(x) &amp; \propto \exp \left(-\frac{1}{2} \cdot \frac{x^2 + \mu^2 - 2\mu x}{\sigma^2}\right) \\
\, \\
&amp; = \exp \left( -\frac{1}{2} \cdot \Big( \frac{1}{\sigma^2}x^2 + \frac{\mu^2}{\sigma^2} - 2\frac{\mu}{\sigma^2}x \Big) \right) \\
&amp; \, \\
&amp; \text{re-ordering:} \\
&amp; = \exp \left( -\frac{1}{2} \cdot \Big(  - 2\frac{\mu}{\sigma^2}x + \frac{1}{\sigma^2}x^2 +  \frac{\mu^2}{\sigma^2} \Big) \right) \\
&amp; \, \\
&amp; \text{coloring:} \\
&amp; = \exp \left( -\frac{1}{2} \cdot \Big( {\color{#004ce9} - 2\frac{\mu}{\sigma^2}x} + {\color{red} \frac{1}{\sigma^2}x^2} +  {\color{#b9b9b9}\frac{\mu^2}{\sigma^2}} \Big) \right) \tag{27} \label{27}
\end{align}\]</span> <br> Now they look even more! Look closely; here we will write down <span class="math inline">\(\eqref{26}\)</span> and <span class="math inline">\(\eqref{27}\)</span> side by side:</p>
<p><span class="math display">\[q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0}) \propto \exp \left(-\frac{1}{2} \cdot \Big( {\color{#004ce9}-2 \big(\frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{\sqrt{\bar\alpha_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_0 \big) \mathbf{x}_{t-1}} + {\color{red} \big( \frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar\alpha_{t-1}}\big)\mathbf{x}^2_{t-1}}\Big) \right)\]</span></p>
<p><span class="math display">\[\text{pdf}(x) \propto \exp \left( -\frac{1}{2} \cdot \Big( {\color{#004ce9} - 2\frac{\mu}{\sigma^2}x} + {\color{red} \frac{1}{\sigma^2}x^2} +  {\color{#b9b9b9}\frac{\mu^2}{\sigma^2}} \Big) \right)\]</span> <br></p>
<p>We can extract a mean and variance from our <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0})\)</span> expression: what’s <span class="math inline">\(\mathbf{x}_{t-1}\)</span> above is just <span class="math inline">\(x\)</span> below (the random variable itself for the distribution)! Therefore, let’s start extracting the red part, which will give us the variance. We can just equal both red expressions and solve for <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[\displaylines{{\color{red}\frac{1}{\sigma^2}} = {\color{red} \frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar\alpha_{t-1}}} \\
\, \\
{\color{red} \sigma^2} = {\color{red} 1 / \big( \frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar\alpha_{t-1}} \big)}}
\]</span> <br></p>
<p>Removing the color and developing a bit:</p>
<p><span class="math display">\[\begin{align}
\sigma^2 &amp; = 1 / \big( \frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar\alpha_{t-1}} \big) \\
\, \\
&amp; \text{with common denominator} \\
&amp; \text{(think that } \bar{\alpha}_{t-1} \cdot \alpha_t = \bar\alpha_t \text{):} \\
&amp; = 1 / \big( \frac{\alpha_t - \bar{\alpha}_t + \beta_t}{\beta_t(1-\bar{\alpha}_{t-1})} \big) \\
\, \\
&amp; \text{remember that } \alpha_t = 1 - \beta_t \text{:} \\
&amp; = 1 / \big( \frac{1 - \bar{\alpha}_t}{(1 - \bar{\alpha}_{t-1})\beta_t} \big) \\
\, \\
&amp; = \frac{(1 - \bar{\alpha}_{t-1})\beta_t}{1 - \bar{\alpha}_t} \\
\, \\
&amp; = \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t \\
\, \\
&amp; \text{coloring:} \\
&amp; = {\color{#ff854c} \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t} \tag{28} \label{28}
\end{align}\]</span> <br></p>
<p>And that’s it for the variance. We can do the same for the mean, by equalling the blue expressions:</p>
<p><span class="math display">\[\displaylines{{\color{#004ce9} - 2\frac{\mu}{\sigma^2}} = {\color{#004ce9}-2 \big(\frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{\sqrt{\bar\alpha_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_0 \big) }\\
\, \\
{\color{#004ce9} \frac{\mu}{\sigma^2}} = {\color{#004ce9} \big(\frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{\sqrt{\bar\alpha_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_0 \big) } \\
\, \\
{\color{#004ce9} \mu} = {\color{#004ce9} \big(\frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{\sqrt{\bar\alpha_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_0 \big) \sigma^2}
}\]</span> <br> And we already did <span class="math inline">\(\sigma^2 = {\color{#ff854c} \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t}\)</span> in <span class="math inline">\(\eqref{28}\)</span>, so we can plug it in and clear the blue color:</p>
<p><span class="math display">\[\begin{align}
\mu &amp; = \big(\frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{\sqrt{\bar\alpha_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_0 \big) {\color{#ff854c} \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t} \\
&amp; \, \\
&amp; \text{multiplying (remember that } \bar{\alpha}_t = \prod_{s=1}^T \alpha_s\text{ as seen in } \eqref{3} \text{):} \\
&amp; = \frac{\sqrt{\alpha}_t(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t}\mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t}\mathbf{x}_0 \tag{29} \label{29}
\end{align}\]</span> <br></p>
<p>Due to the Nice™ property <span class="math inline">\(\eqref{6}\)</span> and the reparametrization trick <span class="math inline">\(\eqref{4}\)</span>, we know that <span class="math inline">\(\mathbf{x}_t = \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}\)</span> — where <span class="math inline">\(\boldsymbol{\epsilon}\)</span> is the added Gaussian noise <span class="math inline">\(\sim \mathcal{N}(0, \mathbf{I})\)</span>. Re-arranging this expression we can get <span class="math inline">\(\mathbf{x}_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 -  \bar{\alpha}_t}\boldsymbol{\epsilon})\)</span>. This way we can replace <span class="math inline">\(\mathbf{x}_0\)</span> and express everything in <span class="math inline">\(\eqref{29}\)</span> terms of <span class="math inline">\(\mathbf{x}_t\)</span>:</p>
<p><span class="math display">\[\begin{align}
\mu &amp; = \frac{\sqrt{\alpha}_t(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t}\mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t}\frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 -  \bar{\alpha}_t}\boldsymbol{\epsilon})\\
&amp; \, \\
&amp; \text{given that } \bar{\alpha}_{t-1} \cdot \alpha_t = \bar\alpha_t \text{; } \,\, \text{then } \bar\alpha_{t-1} / \bar\alpha_t = 1 / \alpha_t \text{; } \\
&amp; \text{and also } \sqrt{\bar\alpha_{t-1}} / \sqrt{\bar\alpha_t} = 1 / \sqrt{\alpha_t} \text{;}\\
&amp; \text{so we can use this last expression to develop}: \\
&amp; = \frac{\sqrt{\alpha}_t(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t}\mathbf{x}_t + \frac{\beta_t}{1 - \bar\alpha_t} \frac{1}{\sqrt{\alpha_t}} (\mathbf{x}_t - \sqrt{1 -  \bar{\alpha}_t}\boldsymbol{\epsilon})\\
&amp; \, \\
&amp; \text{developing products (remember that } \beta_t = 1 - \alpha_t \text{)} \\
&amp; \text{and by the properties of exponents: } \sqrt{(1 - \bar\alpha_t)} / (1 - \bar\alpha_t) = 1 / \sqrt{1 - \bar\alpha_{t}} \text{:}\\
&amp; = \frac{\sqrt{\alpha}_t}{1 - \bar\alpha_t}\mathbf{x}_t - \frac{\sqrt{\alpha_t}\bar\alpha_{t-1}}{1 - \bar\alpha_t}\mathbf{x}_t + \frac{1}{\sqrt{\alpha_t}} \left( \frac{1 - \alpha_t}{1 - \bar\alpha_t}\mathbf{x}_t - \frac{1}{\sqrt{1-\bar\alpha_t}}\beta_t\boldsymbol{\epsilon} \right)\\
&amp; \, \\
&amp; \text{re-arranging:}\\
&amp; = \frac{\sqrt{\alpha_t} - \sqrt{\alpha_t}\bar\alpha_{t-1} + \frac{1-\alpha_t}{\sqrt{\alpha_t}}}{1 - \bar\alpha_t} \mathbf{x}_t + \frac{1}{\sqrt{1 - \bar\alpha_t}} \frac{\beta_t\boldsymbol{\epsilon}}{\sqrt{\alpha_t}} \\
&amp; \, \\
&amp; \text{multiplying in numerator and denominator by } \sqrt{\alpha_t} \text{ in the first summand:}\\
&amp; = \frac{\alpha_t - \alpha_t\bar\alpha_{t-1} + 1 - \alpha_t}{\sqrt{\alpha_t}(1 - \bar\alpha_t)}\mathbf{x}_t + \frac{1}{\sqrt{1 - \bar\alpha_t}} \frac{\beta_t\boldsymbol{\epsilon}}{\sqrt{\alpha_t}} \\
&amp; \, \\
&amp; \text{simplifying the numerator (remember that } \alpha_t  \cdot \bar{\alpha}_{t-1} = \bar\alpha_t \text{):}\\
&amp; = \frac{1 - \bar\alpha_t}{\sqrt{\alpha_t}(1 - \bar\alpha_t)}\mathbf{x}_t + \frac{1}{\sqrt{1 - \bar\alpha_t}} \frac{\beta_t\boldsymbol{\epsilon}}{\sqrt{\alpha_t}} \\
&amp; \, \\
&amp; \text{grouping:}\\
&amp; = \frac{1}{\sqrt{\alpha_t}} \left( \frac{1-\bar\alpha_t}{1 - \bar\alpha_t} \mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar\alpha_t}} \boldsymbol{\epsilon}\right) \\
&amp; \, \\
&amp; \text{and finally:} \\
&amp; = {\color{#70ccf9} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon} \Big)} \tag{30} \label{30}
\end{align}\]</span> <br></p>
<p>To summarize: we have stated that the forward process posterior <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t})\)</span> can be tractable if we condition it on <span class="math inline">\(\mathbf{x}_0\)</span> and if it is a Normal distribution; and we have computed analytically what would be the mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span> of such distribution. If we go back to <span class="math inline">\(\eqref{22}\)</span> we will see that we defined the forward process posterior as:</p>
<p><span class="math display">\[q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0}) = \mathcal{N}(\mathbf{x}_{t-1};{\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})},{\color{red}\tilde{\beta}_t \mathbf{I}})\]</span> <br> Those <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> that we just computed in <span class="math inline">\(\eqref{30}\)</span> and <span class="math inline">\(\eqref{28}\)</span> are <span class="math inline">\({\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})}\)</span> and <span class="math inline">\({\color{red}\tilde{\beta}_t}\)</span> respectively (you can skim again through this appendix to see that this was the whole point of this section). Therefore, we can finally write:</p>
<p><span class="math display">\[{\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})} = {\color{#70ccf9} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon} \Big)} \qquad \text{and} \qquad {\color{red}\tilde{\beta}_t} = {\color{#ff854c} \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t} \tag{31} \label{31}\]</span> <br> As seen in Equation <span class="math inline">\((7)\)</span> of the DDPM paper. Well: actually they show <span class="math inline">\({\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})}\)</span> as we had it in <span class="math inline">\(\eqref{29}\)</span> before we were done developing it; so they show <span class="math inline">\({\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})} = \frac{\sqrt{\alpha}_t(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t}\mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t}\mathbf{x}_0\)</span> (just with the summands in opposite order). Nevertheless, our final derivation in <span class="math inline">\(\eqref{30}\)</span> will become very handy to finalize the definition of our model’s training process.<br></p>
<p><em>Note: in the DDPM paper it looks like their Equation <span class="math inline">\((7)\)</span> is just something the authors conveniently defined (hence the assignment operators they use), but the actual reason why they were defined this way is the full development we have done through this section. We believe that Ho et al.&nbsp;decided that explaining the derivation was cumbersome and would not add much to the conversation and therefore defined <span class="math inline">\({\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})}\)</span> and <span class="math inline">\({\color{red}\tilde{\beta}_t}\)</span> directly without any explanation on how.</em><br></p>
<p>To summarize: the forward process posterior is what our model will try to replicate. Therefore, we need to be able to compute it during training so our model can try to learn from it. Through this section we have concluded that the forward process posterior <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0})\)</span> is also a Normal distribution <span class="math inline">\(\mathcal{N}(\mathbf{x}_{t-1};{\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})},{\color{red}\tilde{\beta}_t \mathbf{I}})\)</span> in which <span class="math inline">\({\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})} = {\color{#70ccf9} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon} \Big)}\)</span> and <span class="math inline">\({\color{red}\tilde{\beta}_t} = {\color{#ff854c} \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t}\)</span>. This means that we can pick a partially noisy image (or even full Normal noise) <span class="math inline">\(\mathbf{x}_t\)</span> and compute a slightly less noisy image <span class="math inline">\(\mathbf{x}_{t-1}\)</span> out of it, therefore reversing the forward diffusion process. If we train a model able to replicate this but without requiring <span class="math inline">\(\mathbf{x}_0\)</span>, we will be able to generate noiseless images out of pure Normal noise!<br><br></p>
<hr>
</section>
<section id="d.-objective-the-training-procedure" class="level1">
<h1>D. Objective &amp; the training procedure</h1>
<p>In <a href="#b.-diffusion-loss-function-elbo-derivation">Appendix B</a> we stated that the training will be focused on the <span class="math inline">\(L_{t-1}\)</span> term from the ELBO:</p>
<p><span class="math display">\[L_{t-1} =  \mathbb{E}_{q} \left[ \mathcal{D}_{\text{KL}} (q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \mid\mid p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)) \right] \tag{32} \label{32}\]</span><br></p>
<p>We want to minimize the KL divergence between those two terms: the “perfect” reverse diffusion (forward process posterior) and the reverse diffusion that our model will learn to do. The first term <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0)\)</span> is the forward process posterior conditioned on <span class="math inline">\(\mathbf{x}_0\)</span>. In <a href="#c.-the-forward-process-posterior">Appendix C</a> we showed that it is a Normal distribution defined in <span class="math inline">\(\eqref{22}\)</span> as:</p>
<p><span class="math display">\[q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0}) = \mathcal{N}(\mathbf{x}_{t-1};{\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})},{\color{red}\tilde{\beta}_t \mathbf{I}})\]</span><br></p>
<p>And throughout the appendix we developed the expression, concluding in <span class="math inline">\(\eqref{31}\)</span> that:</p>
<p><span class="math display">\[{\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})} = {\color{#70ccf9} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon} \Big)} \qquad \text{and} \qquad {\color{red}\tilde{\beta}_t} = {\color{#ff854c} \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t}\]</span><br> For the second term in the KL divergence we have <span class="math inline">\(p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\)</span>, which is what we will predict with our model. Because we will build a model to predict it, we are free to choose basically any form we want for it (as long as we develop the model consequently). Unsurprisingly, the DDPM authors decided that given that we are free to choose, the easiest would be for <span class="math inline">\(p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\)</span> to also be a Normal distribution, in the form of:</p>
<p><span class="math display">\[ p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; {\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)}, {\color{Thistle}\Sigma_\theta(\mathbf{x}_t, t)}) \tag{33} \label{33}\]</span> <br> As described in slide 17. You can see that <span class="math inline">\(\eqref{22}\)</span> and <span class="math inline">\(\eqref{33}\)</span> are very similar. Let’s write down both again:</p>
<p><span class="math display">\[\begin{align}
q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0}) &amp;= \mathcal{N}(\mathbf{x}_{t-1};{\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})},{\color{red}\tilde{\beta}_t \mathbf{I}})\\
\, \\
p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t) &amp;= \mathcal{N}(\mathbf{x}_{t-1}; {\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)}, {\color{Thistle}\Sigma_\theta(\mathbf{x}_t, t)})
\end{align}\]</span> <br> Since we want to minimize the KL divergence between these two terms, it now becomes evident that a way to do it is by making the latter’s mean and variance match the former’s ones! Let’s continue, because the authors end up setting an equivalent yet different goal.<br></p>
<p>Let’s start with the variance. In Section 3.2 of the DDPM paper, the authors define <span class="math inline">\({\color{Thistle}\Sigma_\theta(\mathbf{x}_t, t)} = \sigma^2_t \mathbf{I}\)</span>, and then define <span class="math inline">\(\sigma^2_t\)</span> as:</p>
<p><span class="math display">\[\qquad\qquad\qquad \sigma^2_t = \beta_t \qquad \text{or} \qquad \sigma^2_t = {\color{red}\tilde{\beta}_t} = {\color{#ff854c} \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t} \tag{34} \label{34}\]</span></p>
<p>So they give two possibilities/alternatives here. Intuitively, it would make sense to use the second expression (therefore claiming that <span class="math inline">\({\color{Thistle}\Sigma_\theta(\mathbf{x}_t, t)} = {\color{red}\tilde{\beta}_t \mathbf{I}}\)</span>, which would make both variances match exactly). However, the authors claim that both possibilities are valid and yielded similar results. The first option makes the assumption that the “amount” of noise to be removed in the reverse process should be the same as the one added in the forward process (<span class="math inline">\(\beta_t\)</span>). The second option uses the variance we computed analytically for the forward process posterior (the orange expression).</p>
<p>With that said, either option for <span class="math inline">\(\sigma^2\)</span> implies that there are not any learnable weights/parameters for the variance (as both options can be just computed without any prediction; they only depend on our choice for <span class="math inline">\(\beta_t\)</span>). Hence, we won’t really care about variance during training. However, we will use <span class="math inline">\(\sigma^2\)</span> in the sampling algorithm (after training, when we will actually generate new images).</p>
<p>As for the mean, an obvious choice would be to try to make <span class="math inline">\({\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)}\)</span> match <span class="math inline">\({\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})}\)</span>, which would basically involve learning a model <span class="math inline">\({\color{green}\boldsymbol{\mu}_\theta}\)</span> that predicts <span class="math inline">\({\color{#004ce9}\tilde{\boldsymbol{\mu}}_t}\)</span>: a neural network that tries to predict the mean of the forward process posterior. While this is definitely an option, the authors decided to do something slightly different (although other papers explore this possibility).</p>
<p>In the end, they decided to do the following: they built <strong>a model that learns to predict the noise</strong> that was added during the forward process. Let’s see how they did it.</p>
<p>Going back to the definition of <span class="math inline">\(L_{t-1}\)</span> in <span class="math inline">\(\eqref{32}\)</span>, we can see that this is the KL divergence between the forward process posterior and the reverse process that we are trying to learn with a model. Given that we stated that these two are multivariate Normal distributions, the KL divergence has a closed form formula. Let’s develop it.</p>
<p>We will start by defining <span class="math inline">\(\mathcal{N}_0\)</span> and <span class="math inline">\(\mathcal{N}_1\)</span> as two multivariate Normal distributions for which we want to compute the KL divergence, with their respective means <span class="math inline">\(\boldsymbol\mu_0\)</span> and <span class="math inline">\(\boldsymbol\mu_1\)</span> and covariance matrices <span class="math inline">\(\Sigma_0\)</span> and <span class="math inline">\(\Sigma_1\)</span>. <span class="math inline">\(k\)</span> is the number of dimensions (which is always also the length of the vectors <span class="math inline">\(\boldsymbol\mu_0\)</span> and <span class="math inline">\(\boldsymbol\mu_1\)</span> as well as the rows and columns of the matrices <span class="math inline">\(\Sigma_0\)</span> and <span class="math inline">\(\Sigma_1\)</span>) and it is there since we are working multivariate Normals. With this notation, <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Multivariate_normal_distributions" target="_blank">we can define the KL divergence between <span class="math inline">\(\mathcal{N}_0\)</span> and <span class="math inline">\(\mathcal{N}_1\)</span> as follows</a>:</p>
<p><span class="math display">\[
\mathcal{D}_{\text{KL}}(\mathcal{N}_0 \mid \mid \mathcal{N}_1) = \frac{1}{2} \left( \text{tr}(\Sigma_1^{-1} \Sigma_0) - k + (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0)^\top \cdot \Sigma_1^{-1} \cdot (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0) + \ln\left(\frac{\det \Sigma_1}{\det \Sigma_0} \right) \right)\]</span> <br> In our case, we can assume the (co)variances of the two Normals to be the same (as discussed earlier in this section) and set them to <span class="math inline">\(\sigma^2_t \mathbf{I}\)</span>, stating that <span class="math inline">\(\Sigma_0 = \Sigma_1\)</span>. By doing so, the KL divergence formula greatly simplifies:</p>
<p><span class="math display">\[\begin{align}
\mathcal{D}_{\text{KL}}(\mathcal{N}_0 \mid \mid \mathcal{N}_1) &amp;= \frac{1}{2} \left( \text{tr}(\Sigma_1^{-1} \Sigma_0) - k + (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0)^\top \cdot \Sigma_1^{-1} \cdot (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0) + \ln\left(\frac{\det \Sigma_1}{\det \Sigma_0} \right) \right) \\
\, \\
&amp; \text{given that } \Sigma_1^{-1} \Sigma_0 = \mathbf{I} \text{ and that } \text{tr}(\mathbf{I})=k \text{ :}\\
&amp; = \frac{1}{2} \left( k - k + (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0)^\top \cdot \Sigma_1^{-1} \cdot (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0) + \ln 1\right) \\
\, \\
&amp; = \frac{1}{2} \left((\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0)^\top \cdot \Sigma_1^{-1} \cdot (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0) \right)\\
\, \\
&amp; \text{we stated that } \Sigma_0 = \Sigma_1 = \sigma_t^2\mathbf{I} \text{ :}\\
&amp; = \frac{1}{2} \left((\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0)^\top \cdot (\sigma^2_t \mathbf{I})^{-1} \cdot (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0) \right)\\
\, \\
&amp; \text{we can just write } \sigma_t^2\mathbf{I} \text{ in scalar form without the } \mathbf{I}\text{,}\\
&amp; \text{and perform multiplication/division with the means}\\
&amp; \text{as scalar-vector products:}\\
&amp; = \frac{1}{2 \sigma_t^2} \left((\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0)^\top \cdot (\boldsymbol{\mu}_1 - \boldsymbol{\mu}_0) \right)\\
\, \\
&amp; \text{the dot product of a vector with itself is just}\\
&amp; \text{the square of its } \href{https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm}{L^2 \text{ norm}}\text{:}\\
&amp; = \frac{1}{2 \sigma_t^2} \left \lVert \boldsymbol{\mu}_1 - \boldsymbol{\mu}_0 \right \rVert^2_2 \tag{35} \label{35}\\
\end{align}\]</span> <br> Going back to our case, we can now apply <span class="math inline">\(\eqref{35}\)</span> and write the KL divergence in <span class="math inline">\(\eqref{32}\)</span> as:</p>
<p><span class="math display">\[\begin{align}
L_{t-1} &amp; =  \mathbb{E}_{q} \left[ \mathcal{D}_{\text{KL}} (q(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0) \mid\mid p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)) \right] \\
\, \\
&amp; = \mathbb{E}_{q} \left[ \frac{1}{2 \sigma_t^2} \left \lVert {\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})} - {\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)} \right \rVert^2_2 \right] \tag{36} \label{36}
\end{align}\]</span> <br> <em>Note: You will find a very similar expression to this one in Equation <span class="math inline">\((8)\)</span> of the DDPM paper. However, in the paper you will see a new constant <span class="math inline">\(C\)</span>. This constant appears if we assume that both Normal distributions do not have the same (co)variance. If that is the case, some of the simplifications we just did do not apply anymore (namely, the trace and the logarithm). Nevertheless, neither of those non-simplified elements depend on <span class="math inline">\(\boldsymbol{\mu}_\theta\)</span>, so these can be treated as constants for the purposes of optimization (and therefore they don’t affect the result).</em></p>
<p>Let’s now define a form for what will be the predicted mean <span class="math inline">\({\color{green}\boldsymbol{\mu}}\)</span>. We showed in <span class="math inline">\(\eqref{31}\)</span> that <span class="math inline">\({\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})} = {\color{#70ccf9} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon} \Big)}\)</span>. We can choose an analogous form for <span class="math inline">\({\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)}\)</span>, and write the following parametrization:</p>
<p><span class="math display">\[ {\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)} = {\color{GreenYellow} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big)} \tag{37} \label{37}\]</span> <br> As seen in Equation <span class="math inline">\((11)\)</span> of the DDPM paper; where <span class="math inline">\({\color{#70ccf9}\boldsymbol{\epsilon}}\)</span> is the added gaussian noise <span class="math inline">\(\mathcal{N}(0, \mathbf{I})\)</span> in the forward pass, and <span class="math inline">\({\color{GreenYellow}\boldsymbol{\epsilon}_\theta}\)</span> will be our actual neural network, which will be given the task to predict the added noise in the forward process <span class="math inline">\({\color{#70ccf9}\boldsymbol{\epsilon}}\)</span> using <span class="math inline">\(\mathbf{x}_t\)</span> and <span class="math inline">\(t\)</span> as features. During training we will generate a noisy image, picking an original image at random from our training set and applying the Nice™ property with a random value of <span class="math inline">\(t\)</span> and random noise <span class="math inline">\({\color{#70ccf9}\boldsymbol{\epsilon}}\)</span> to make it more or less noisy depending on the value obtained for <span class="math inline">\(t\)</span>. Adding that chosen value of <span class="math inline">\(t\)</span> as a feature for our model is convenient, as it helps the model know <em>how noisy we have made our training image <span class="math inline">\(\mathbf{x}_t\)</span></em> —which can be useful info for our model to help it denoise better.</p>
<p>To sum up, the authors decided to make a model to predict the noise <span class="math inline">\({\color{#70ccf9}\boldsymbol{\epsilon}}\)</span> instead of trying to predict the <em>whole</em> mean of the forward process posterior <span class="math inline">\({\color{#004ce9}\tilde{\boldsymbol{\mu}}_t}\)</span>. It makes sense: we know from <span class="math inline">\(\eqref{31}\)</span> that <span class="math inline">\({\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})} = {\color{#70ccf9} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon} \Big)}\)</span>. Note how every term in this expression will be always known at prediction time except for <span class="math inline">\({\color{#70ccf9}\boldsymbol{\epsilon}}\)</span>. Therefore, we will make the model focus only on trying to predict this last one.</p>
<p>Now, by plugging <span class="math inline">\(\eqref{37}\)</span> and the first part of <span class="math inline">\(\eqref{31}\)</span> into <span class="math inline">\(\eqref{36}\)</span> we can therefore express the loss as:</p>
<p><span class="math display">\[\begin{align}
L_{t-1} &amp; =  \mathbb{E}_{q} \left[ \frac{1}{2 \sigma_t^2} \left \lVert {\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})} - {\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)} \right \rVert^2_2 \right] \\
\, \\
&amp;= \mathbb{E}_{\mathbf{x}_t, \boldsymbol{\epsilon}} \left[ \frac{1}{2 \sigma_t^2} \left \lVert {\color{#70ccf9} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon} \Big)} - {\color{GreenYellow} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big)} \right \rVert^2_2 \right] \\
\, \\
&amp; \text{clearing colors:} \\
&amp;= \mathbb{E}_{\mathbf{x}_t, \boldsymbol{\epsilon}} \left[ \frac{1}{2 \sigma_t^2} \left \lVert \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon} \Big) - \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big) \right \rVert^2_2 \right] \\
\, \\
&amp; \text{multiplying:} \\
&amp;= \mathbb{E}_{\mathbf{x}_t, \boldsymbol{\epsilon}} \left[ \frac{1}{2 \sigma_t^2} \left \lVert \frac{\mathbf{x}_t}{\sqrt{\alpha_t}} -  \frac{\beta_t}{\sqrt{\alpha_t} \sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}  - \frac{\mathbf{x}_t}{\sqrt{\alpha_t}} +  \frac{\beta_t}{\sqrt{\alpha_t} \sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)  \right \rVert^2_2 \right] \\
\, \\
&amp;= \mathbb{E}_{\mathbf{x}_t, \boldsymbol{\epsilon}} \left[ \frac{1}{2 \sigma_t^2} \left \lVert  -  \frac{\beta_t}{\sqrt{\alpha_t} \sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}  +  \frac{\beta_t}{\sqrt{\alpha_t} \sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \right \rVert^2_2 \right] \\
\, \\
&amp; \text{grouping:} \\
&amp;= \mathbb{E}_{\mathbf{x}_t, \boldsymbol{\epsilon}} \left[ \frac{1}{2 \sigma_t^2} \left \lVert  - \frac{\beta_t}{\sqrt{\alpha_t} \sqrt{1-\bar{\alpha}_t}} \left( \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \right) \right \rVert^2_2 \right] \\
\, \\
&amp; \text{taking the factor out of the square:} \\
&amp;= \mathbb{E}_{\mathbf{x}_t, \boldsymbol{\epsilon}} \left[ \frac{1}{2 \sigma_t^2} \left( \frac{\beta_t}{\sqrt{\alpha_t} \sqrt{1-\bar{\alpha}_t}} \right)^2 \left \lVert \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \right \rVert^2_2 \right] \\
\, \\
&amp;= \mathbb{E}_{\mathbf{x}_t, \boldsymbol{\epsilon}} \left[ \frac{\beta_t^2}{2 \sigma_t^2 \alpha_t (1-\bar{\alpha}_t)} \left \lVert \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \right \rVert^2_2 \right] \\
\, \\
&amp; \text{applying the Nice}^{\texttrademark} \text{ property } \eqref{6} \text{ and reparametrization trick } \eqref{4} \text{ to } \mathbf{x}_t \text{:} \\
&amp;= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \left[ \frac{\beta_t^2}{2 \sigma_t^2 \alpha_t (1-\bar{\alpha}_t)} \left \lVert \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}, t) \right \rVert^2_2 \right] \tag{38} \label{38}
\end{align}\]</span> <br> As seen in Equation <span class="math inline">\((12)\)</span> of the DDPM paper (they omit the subscript in the <span class="math inline">\(L^2\)</span> norm, but it is implicitly there. It’s just a matter of different notation).</p>
<p>This formula is, literally, the mean squared error between our model’s prediction and the added noise during the forward pass, multiplied by some term <span class="math inline">\(\frac{\beta_t^2}{2 \sigma_t^2 \alpha_t (1-\bar{\alpha}_t)}\)</span>. This can be thought of as a weighting term, and its value basically depends on <span class="math inline">\(t\)</span>, which again: tells us how noisy we have made the image we are learning from. This means that this weighting term upweights the loss value for images with a high <span class="math inline">\(t\)</span>, therefore, the most noisy ones. It basically forces the model to focus more on the problem of predicting correctly the noise in images with lots of noise, whereas predicting well the noise for less noisy images becomes less relevant.</p>
<p>However, the authors state in Section 3.4 that it is both simpler and better for image quality to disregard this term. Hence, the final loss function becomes:</p>
<p><span class="math display">\[L_\text{simple} \coloneqq \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}, t} \left[ \left \lVert \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}, t) \right \rVert^2_2 \right] \tag{39} \label{39}\]</span> <br> Which straight up is the mean squared error between the model’s prediction and the added noise to the image sample.</p>
<p>Therefore, the training process is as simple as it is shown in Algorithm 1 of the DDPM paper:</p>
<blockquote class="blockquote">
<p><span class="math inline">\(\textbf{Algorithm 1} \,\,\, \text{Training}\)</span></p>
<p><span class="math inline">\(1:\, \textbf{repeat}\)</span><br>
<span class="math inline">\(2: \quad \mathbf{x}_0 \sim q(\mathbf{x}_0)\)</span><br>
<span class="math inline">\(3: \quad t \sim \text{Uniform}(\{1,\ldots,T\})\)</span><br>
<span class="math inline">\(4: \quad \boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})\)</span><br>
<span class="math inline">\(5: \quad \text{Take gradient descent step on}\)</span><br>
<span class="math inline">\(\qquad\qquad\nabla_\theta\,\left\lVert\boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}, t) \right \rVert^2_2\)</span><br>
<span class="math inline">\(6:\, \textbf{until} \text{ converged}\)</span></p>
</blockquote>
<p>Which can be summarized as: pick a training image, pick a random value for <span class="math inline">\(t\)</span>, use the Nice™ property to make the image noisy according to the picked <span class="math inline">\(t\)</span>, input that noisy image to the model together with <span class="math inline">\(t\)</span> itself, and use the mean squared error of the predicted vs real added noise as the loss to train the model.</p>
<p>For all the complexity we got from all theory and derivations, we end up with a surprisingly simple formulation for model training. <br><br></p>
<hr>
</section>
<section id="e.-the-sampling-procedure" class="level1">
<h1>E. The sampling procedure</h1>
<p>After training, we can generate new images out of random Normal noise. The inference (prediction) procedure is usually known as <em>sampling</em> in diffusion models, and it is implemented in Algorithm 2 of the DDPM paper:</p>
<span id="algo2" <="" span="">
<blockquote class="blockquote">
<p><span class="math inline">\(\textbf{Algorithm 2} \,\,\, \text{Sampling}\)</span></p>
<p><span class="math inline">\(1:\, \mathbf{x}_T \sim \mathcal{N}(0, \mathbf{I})\)</span><br>
<span class="math inline">\(2:\, \textbf{for } t = T,\ldots,1 \textbf{ do}\)</span><br>
<span class="math inline">\(3: \quad \mathbf{z} \sim \mathcal{N}(0, \mathbf{I}) \text{ if } t&gt;1\text{, else } \mathbf{z}=0\)</span><br>
<span class="math inline">\(4: \quad \mathbf{x}_{t-1} = \frac{1}{\sqrt{\alpha_t}}\left( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar\alpha_t}}\boldsymbol{\epsilon}_\theta (\mathbf{x}_t, t) \right) + \sigma_t \mathbf{z}\)</span><br>
<span class="math inline">\(5:\, \textbf{end for}\)</span><br>
<span class="math inline">\(6:\, \textbf{return } \mathbf{x}_0\)</span></p>
</blockquote>
<p>We can summarize it as: generate some <span class="math inline">\(\mathcal{N}(0, \mathbf{I})\)</span> noise and call it our initial extremely noisy image <span class="math inline">\(\mathbf{x}_T\)</span>, and over a number of steps <span class="math inline">\(T\)</span> predict the noise using the trained model, and subtract <em>part of</em> that predicted noise (through scaling it) to get a slightly less noisy image. Additionally, we also add some extra noise through <span class="math inline">\(\sigma_t \mathbf{z}\)</span> (!?). This slightly less noisy image is the input for the next iteration. We repeat this process <span class="math inline">\(T\)</span> times, and the image gets progressively denoised. At the end of the process, we get back a (hopefully) new, noiseless image. <br></p>
<p>With this process in mind, you will most likely have two questions:</p>
<ol type="1">
<li><p>If at any given step <span class="math inline">\(t\)</span> we are using our trained model <span class="math inline">\({\color{GreenYellow}\boldsymbol{\epsilon}_\theta}\)</span> to predict <span class="math inline">\({\color{#70ccf9}\boldsymbol{\epsilon}}\)</span>, which is the noise we added through the forward process, <strong>why don’t we remove it in a single step?</strong> Why go through the trouble of doing <span class="math inline">\(T\)</span> steps of progressive denoising?</p></li>
<li><p>What on Earth is <span class="math inline">\(\sigma_t \mathbf{z}\)</span> and why is it there? It is adding back Normal noise to the image in the middle of our denoising process! For all the trouble we got to learn a model capable of denoising, <strong>why are we adding noise back again</strong> in order to denoise an image??</p></li>
</ol>
<p>Let’s address these two questions. To do so, we will present two answers: the mathematical one and the intuitive one. <br></p>
<section id="e.1.-the-mathematical-answer" class="level2">
<h2 class="anchored" data-anchor-id="e.1.-the-mathematical-answer">E.1. The mathematical answer</h2>
<p>This one is pretty short and very straightforward, and will answer both questions at once: <em>it’s just how we have defined the process</em>. It’s very simple:</p>
<ol type="1">
<li><p>We have defined a forward diffusion process <span class="math inline">\(q(\mathbf{x}_t \mid \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I})\)</span> where given some potentially partially noisy image <span class="math inline">\(\mathbf{x}_{t-1}\)</span> it returns a slightly noisier image <span class="math inline">\(\mathbf{x}_t\)</span></p></li>
<li><p>We also defined in <a href="#c.-the-forward-process-posterior">Appendix C</a> the forward process posterior <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0}) = \mathcal{N}(\mathbf{x}_{t-1};{\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})},{\color{red}\tilde{\beta}_t \mathbf{I}})\)</span>, which does the same in reverse (conditioning on <span class="math inline">\(\mathbf{x}_0\)</span>, but that is irrelevant now): Given a noisy image <span class="math inline">\(\mathbf{x}_t\)</span> it returns a slightly less noisy one <span class="math inline">\(\mathbf{x}_{t-1}\)</span></p></li>
<li><p>To have a model that learns to do the same that the forward process posterior does, we defined in <a href="#d.-objective-the-training-procedure">Appendix D</a> the reverse diffusion process <span class="math inline">\(p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; {\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)}, {\color{Thistle}\Sigma_\theta(\mathbf{x}_t, t)})\)</span> that does the same as the forward process posterior: Given a noisy image <span class="math inline">\(\mathbf{x}_t\)</span> it returns a slightly less noisy one <span class="math inline">\(\mathbf{x}_{t-1}\)</span></p></li>
</ol>
<p>This means that given how we have defined all the logic, the way to proceed is to get a fully noisy image (or a <span class="math inline">\(\mathbf{x}_t \sim \mathcal{N}(0, \mathbf{I})\)</span>) and apply succesively <span class="math inline">\(p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\)</span> to it until we get to <span class="math inline">\(\mathbf{x}_0\)</span>. <br><br></p>
<p>As seen in Appendix D, the reverse process <span class="math inline">\(p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\)</span> is a Normal distribution <span class="math inline">\(\mathcal{N}(\mathbf{x}_{t-1}; {\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)}, {\color{Thistle}\Sigma_\theta(\mathbf{x}_t, t)})\)</span> with mean <span class="math inline">\({\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)} = {\color{GreenYellow} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big)}\)</span> and variance <span class="math inline">\({\color{Thistle}\Sigma_\theta(\mathbf{x}_t, t)} = \sigma^2_t \mathbf{I}\)</span> (where <span class="math inline">\(\sigma^2_t = \beta_t\)</span> or <span class="math inline">\(\sigma^2_t = {\color{red}\tilde{\beta}_t} = {\color{#ff854c} \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t}\)</span>).</p>
<p>As with any Normal distribution, we can apply the reparametrization trick as seen in <span class="math inline">\(\eqref{4}\)</span>. If we apply it, we will get the following (here we call the noise <span class="math inline">\(\mathbf{z}\)</span> instead of <span class="math inline">\(\boldsymbol{\epsilon}\)</span> to tell them apart, but both are just <span class="math inline">\(\mathcal{N}(0, \mathbf{I})\)</span>):</p>
<p><span class="math display">\[\begin{align}
\mathbf{x}_{t-1} &amp;= {\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)} + \sqrt{{\color{Thistle}\Sigma_\theta(\mathbf{x}_t, t)}} \cdot \mathbf{z}, \qquad \mathbf{z} \sim \mathcal{N}(0, \mathbf{I}) \\
\, \\
&amp;= {\color{GreenYellow} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big)} + \sqrt{\sigma_t^2} \cdot z \\
\, \\
&amp; \beta_t = 1 - \alpha_t \text{ as we know from } \eqref{2} \text{:} \\
&amp;= {\color{GreenYellow} \frac{1}{\sqrt{\alpha_t}} \Big(\mathbf{x}_t -  \frac{1 - \alpha_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big)} + \sigma_t \cdot z
\end{align}\]</span> <br></p>
<p>Now take a look again at step 4 in <a href="#algo2">Algorithm 2</a>. It’s exactly the same! That is because this is literally where it comes from: it is just a matter of applying the reparametrization trick to <span class="math inline">\(p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t)\)</span>.</p>
<p>This uncovers an important fact about how the process has been designed: <strong>the forward process posterior</strong> <span class="math inline">\(q(\mathbf{x}_{t-1} \mid \mathbf{x}_{t},\mathbf{x}_{0}) = \mathcal{N}(\mathbf{x}_{t-1};{\color{#004ce9}\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_{t},\mathbf{x}_{0})}, {\color{red}\tilde{\beta}_t \mathbf{I}})\)</span> that we have depicted as the “perfect reverse difffusion process” is, in essence, <strong>non-deterministic</strong>, as it is a Normal distribution with a variance greater than zero (<span class="math inline">\({\color{red}\tilde{\beta}_t}\)</span> is <span class="math inline">\(&gt;0\)</span>). And sampling data from a Normal distribution with a variance greater than zero will give us different numbers every time we sample from it. This means that if we run the forward process to get to full noise <span class="math inline">\(\mathbf{x}_T\)</span> and then the forward process posterior to get back to <span class="math inline">\(\mathbf{x}_0\)</span>, most likely we won’t get the exact same original image, but rather a closely similar one. In fact, each time we run the forward process posterior we will get a slightly different image (unless we set the random seed constant, of course). Therefore, even the forward process posterior is somewhat noisy—as it incorporates noise.</p>
<p>And the exact same goes for our learned reverse process <span class="math inline">\(p_\theta(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; {\color{green}\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)}, {\color{Thistle}\Sigma_\theta(\mathbf{x}_t, t)})\)</span>. This is why there is noise/randomness in step 4 in the Algorithm.</p>
<p>If that answers your questions about why we perform many steps in the sampling algorithm and why we still add back more noise during the process, then good for you. However, even if math is clear you may still find it conceptually confusing. Don’t worry: you are not alone. Let’s go through another way to answer those two questions. <br><br></p>
</section>
<section id="e.2.-the-intuitive-answer" class="level2">
<h2 class="anchored" data-anchor-id="e.2.-the-intuitive-answer">E.2. The intuitive answer</h2>
<p>Now that we understand all the math behind DDPMs, let’s jump into how the process works conceptually. Arguably the most important intuition is how noising an image works.</p>
<p>During the forward process, we incrementally add Normal noise to the image. As we saw in slide 14, it boils down to creating some <span class="math inline">\(\mathcal{N}(0, \beta_t \mathbf{I})\)</span> data and adding it to the (scaled) <span class="math inline">\(\mathbf{x}_{t-1}\)</span> image to get <span class="math inline">\(\mathbf{x}_t\)</span>. As a shorthand, we can also write it down as <span class="math inline">\(q(\mathbf{x}_t \mid \mathbf{x}_{t-1}) \coloneqq \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I})\)</span>, but it is the exact same thing.</p>
<p>To better understand what adding this noise looks like, we will use some data from the <a href="https://paperswithcode.com/dataset/afhq">Animal Faces-HQ dataset</a> (version 2), a dataset created by <a href="https://arxiv.org/abs/1912.01865" target="_blank">Choi et al.&nbsp;[2020]</a> which features many photos of animal faces. We will only use dog faces for this example.</p>
<p>All images in the dataset are high-quality 512x512 photos, which means that data is very high-dimensional: 512 pixels of height x 512 pixels of width x 3 color channels (RGB) = 786,432. So if we were to <em>flatten out</em> the images, these would “live” in a 786,432-dimensional space!</p>
<p>Unfortunately, we cannot represent 786,432 dimensions on a flat screen. Therefore, we will represent the dimensional space where our dog faces lie scattered in a 2D plane. Keep in mind that our intuitions about the 2D (or 3D) space don’t fully apply to very high-dimensional spaces (due to the <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" target="_blank">curse of dimensionality</a> among other issues), but this is still the best we can do.</p>
<p><em>Note: We would like to thank <a href="https://x.com/sedielem" target="_blank">Sander Dieleman</a> from Deepmind, as the upcoming diagrams were inspired by <a href="https://sander.ai/2023/08/28/geometry.html" target="_blank">his article on diffusion guidance</a>.</em></p>
<p>Here is the dimensional space we will work with. We are already showing one of the images in our dataset. We will call it <span class="math inline">\(\mathbf{x}_0\)</span> since it is an original, noiseless image:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_forward_process_0.png" class="withborder img-fluid figure-img"></p>
<figcaption>The dimensional space where our dog face photos live</figcaption>
</figure>
</div>
<p><br> All possible dog faces are points in this dimensional space. However, most points will be just noisy, nonsensical images instead of recognizable dog faces—realistic dog faces will most likely only be present in very narrow, specific parts of this space (think about the probability of getting a good looking dog face just by randomly selecting RGB values for 512x512 pixels).</p>
<p>Nevertheless, here we have our <span class="math inline">\(\mathbf{x}_0\)</span> image. During the forward diffusion process we add noise to this image progressively, across <span class="math inline">\(T\)</span> steps. In each of these steps we generate <span class="math inline">\(\mathcal{N}(0, \beta_t \mathbf{I})\)</span> data and add it to the image. Effectively, it can be thought of as “jumping” from the current position of <span class="math inline">\(\mathbf{x}_0\)</span> to another point in the space.</p>
<p>A good way to understand the mean and variance of the generated noise is to think in terms of vectors:</p>
<ul>
<li>The mean represents the direction for the vector (the direction in which we jump)</li>
<li>The variance represents how long (or short) that vector is (how long our jump is)</li>
</ul>
<p>Since the mean of the noise we generate is <span class="math inline">\(0\)</span>, the actual sampled values will be something around zero, but can be positive or negative (most likely something like <span class="math inline">\(0.41\)</span>, <span class="math inline">\(-0.17\)</span>, <span class="math inline">\(1.03\)</span>…) which means that the direction we will take in order to perform the jump is purely random: it could be left, right, up, down, or any combination of those. As for the variance: we set it to <span class="math inline">\(\beta_t\)</span>, which is usually a small value. This means that we will make a small jump (we will depict it as a relatively large jump for illustrative purposes). Therefore, a single forward diffusion step will look like this:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_forward_process_1.png" class="withborder img-fluid figure-img"></p>
<figcaption>The first forward diffusion step <span class="math inline">\(q(\mathbf{x}_1 \mid \mathbf{x}_0)\)</span></figcaption>
</figure>
</div>
<p><br> Due to randomness, we ended up jumping up right. You can see that indeed, <span class="math inline">\(\mathbf{x}_1\)</span> is already a bit noisy (but still very much recognizable).</p>
<p>Let’s perform another forward diffusion step. Just like in the first one, we will jump in a random direction, but now from <span class="math inline">\(\mathbf{x}_1\)</span>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_forward_process_2.png" class="withborder img-fluid figure-img"></p>
<figcaption>Second forward diffusion step <span class="math inline">\(q(\mathbf{x}_2 \mid \mathbf{x}_1)\)</span></figcaption>
</figure>
</div>
<p><br> The image gets noisier and further away from the original. If we perform a third step:</p>
<div id="fp3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_forward_process_3.png" class="withborder img-fluid figure-img"></p>
<figcaption>Third forward diffusion step <span class="math inline">\(q(\mathbf{x}_3 \mid \mathbf{x}_2)\)</span></figcaption>
</figure>
</div>
<p><br> And we could continue doing forward steps up to <span class="math inline">\(T\)</span> (where <span class="math inline">\(T=1000\)</span> in the DDPM paper).</p>
<p><em>Note: obviously diagrams are only illustrative, and in reality the third diffusion step does not yield an image as noisy as depicted here; the actual process is much more gradual. Furthermore, the variance <span class="math inline">\(\beta_t\)</span> (jump length) gets progressively higher as defined in the variance schedule (where in the DDPM paper <span class="math inline">\(\beta_1=10^{-4}\)</span> and <span class="math inline">\(\beta_T=0.02\)</span>).</em></p>
<p><br> We also know that due to <a href="#a.-the-nice-property">the Nice™ property</a> we can take shortcuts and go from <span class="math inline">\(\mathbf{x}_0\)</span> to any <span class="math inline">\(\mathbf{x}_t\)</span> directly. This means that we can use the Nice™ property once and create an equivalent <span class="math inline">\(\mathbf{x}_3\)</span> image directly from <span class="math inline">\(\mathbf{x}_0\)</span>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_forward_process_4.png" class="withborder img-fluid figure-img"></p>
<figcaption>The Nice™ property for <span class="math inline">\(q(\mathbf{x}_3 \mid \mathbf{x}_0)\)</span></figcaption>
</figure>
</div>
<p><br> And that’s it for the forward process. Now let’s explain the sampling process, as this will let us answer our two questions about the sampling algorithm. <br></p>
<p>As explained in the sampling algorithm, to generate new images we will start generating a <span class="math inline">\(\mathbf{x}_T\)</span> which is pure <span class="math inline">\(\mathcal{N}(0, \mathbf{I})\)</span> noise. We will also assume that we trained our diffusion model exclusively with images of dog faces. Therefore, our model will only know how to generate dog faces.</p>
<p>Most likely we will want our model to generate noiseless, photorealistic dog faces similar to the ones used for training. We will now place in the 2D space the dog face we have shown in the forward process (which we will still call <span class="math inline">\(\mathbf{x}_0\)</span>), as well as a pure noise image <span class="math inline">\(\mathbf{x}_T\)</span>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_sampling_process_1.png" class="withborder img-fluid figure-img"></p>
<figcaption><span class="math inline">\(\mathbf{x}_0\)</span> and <span class="math inline">\(\mathbf{x}_T\)</span> in our dimensional space</figcaption>
</figure>
</div>
<p><br> You can see that we were unlucky enough to generate random noise that is far away from what would be a good image, such as <span class="math inline">\(\mathbf{x}_0\)</span>. This will happen basically always (again, think of the chance of obtaining a realistic image out of pure random pixels). Therefore, during the sampling process we will want to jump to space locations close to good, realistic dog faces.</p>
<p>Unlike in the forward process—where the direction in which we jumped was random—now we have a model that has learned to predict <span class="math inline">\({\color{#70ccf9}\boldsymbol{\epsilon}}\)</span>, which represents the specific noise that we would have added during the forward diffusion process to get from a realistic image to pure noise. Therefore, the noise to subtract is not random anymore nor has a mean of <span class="math inline">\(0\)</span>, but rather it gives us a specific direction in which we will jump: the opposite direction of <span class="math inline">\({\color{#70ccf9}\boldsymbol{\epsilon}}\)</span>.</p>
<p>As you can imagine, our model will not be perfect. Chances of getting the model to predict the perfect, exact direction that would turn <span class="math inline">\(\mathbf{x}_T\)</span> into <span class="math inline">\(\mathbf{x}_0\)</span> are very slim (basically 0). However, it should still give us a <em>good</em> direction: getting us to the part of the dimensional space where realistic dog faces exist.</p>
<p><br> With that in mind, let’s recover the first question we had about the sampling algorithm:</p>
<blockquote class="blockquote">
<p><em>1. If at any given step <span class="math inline">\(t\)</span> we are using our trained model <span class="math inline">\({\color{GreenYellow}\boldsymbol{\epsilon}_\theta}\)</span> to predict <span class="math inline">\({\color{#70ccf9}\boldsymbol{\epsilon}}\)</span>, which is the noise we added through the forward process, <strong>why don’t we remove it in a single step?</strong> Why go through the trouble of doing <span class="math inline">\(T\)</span> steps of progressive denoising?</em></p>
</blockquote>
<p>To understand why this won’t work well, the best way to proceed is to just try doing it!</p>
<p>We know that the Nice™ property allows us to jump from <span class="math inline">\(\mathbf{x}_0\)</span> to any <span class="math inline">\(\mathbf{x}_t\)</span> (including <span class="math inline">\(\mathbf{x}_T\)</span>), so why don’t we apply the inverse of the Nice™ property to get from <span class="math inline">\(\mathbf{x}_T\)</span> directly to <span class="math inline">\(\mathbf{x}_0\)</span> in a single step?</p>
<p>We can totally do that. The formula is very simple. If we know that the Nice™ property gives us:</p>
<p><span class="math display">\[ \mathbf{x}_t = \sqrt{\bar\alpha_t} \mathbf{x}_{0} + \sqrt{1 - \bar\alpha_t}\boldsymbol{\epsilon}\]</span> <br></p>
<p>The inverse transformation can be obtained by solving for <span class="math inline">\(\mathbf{x}_0\)</span>:</p>
<p><span class="math display">\[ \mathbf{x}_0 = \frac{1}{\sqrt{\bar\alpha_t}} \mathbf{x}_t - \sqrt{1 - \bar\alpha_t}\boldsymbol{\epsilon}\]</span> <br></p>
<p>Where <span class="math inline">\(\boldsymbol{\epsilon}\)</span> will be in our case our model prediction, which gives us the direction we should jump to. Doing it for our example will yield the following:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_sampling_process_2.png" class="withborder img-fluid figure-img"></p>
<figcaption>Applying the Nice™ property in reverse</figcaption>
</figure>
</div>
<p><br> The dashed line shows our model’s predicted direction, and the jump length is basically dictated by the inverse Nice™ property formula itself. We would then end up in a point that we will call <span class="math inline">\(\hat{\mathbf{x}}_0\)</span> (the <span class="math inline">\(\,\hat{ }\,\)</span> indicates it is a prediction, as usual in machine learning)…</p>
<p>… And it looks horrible. We get nothing but a blurry image that <em>kind of</em> looks like a dog face, but quality is extremely low. How is that possible? It is relatively close to our reference image <span class="math inline">\(\mathbf{x}_0\)</span>…</p>
<p>To better understand what is going on, let’s add some more dog faces to our dimensional space. We have obviously trained our model with many dog faces, and all of them lie somewhere in this space. Let’s include two more in our diagram:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_sampling_process_3.png" class="withborder img-fluid figure-img"></p>
<figcaption>Detailing more dog faces in the dimensional space</figcaption>
</figure>
</div>
<p><br> We have added some colored contour areas around each dog to depict the fact that the closer a point is to a dog, the more it will resemble that dog. For instance: a point close to the gray Pitbull at the top will look similar to that gray Pitbull.</p>
<p>Here we can see how our prediction <span class="math inline">\(\hat{\mathbf{x}}_0\)</span> is close to all three dogs. And that’s exactly our problem: our generated image is basically a <em>generic average</em> of the dog images that are close in the space. Let’s explain why this is happening.</p>
<p>As we discussed in <a href="#d.-objective-the-training-procedure">Appendix D</a> our model is trained on the mean squared error between its prediction and the real added noise during the forward process to a partially noisy image <span class="math inline">\(\mathbf{x}_t\)</span>. During the sampling algorithm we start with pure random noise, so the model will most likely not be very accurate predicting what was the added noise (because it’s all noise!). Therefore the model will try to guess what would be the noise that, when subtracted, we could end up with something similar to a dog face. However, the model <em>will not take the risk</em> of assuming that we should end up with a <em>specific</em> dog face.</p>
<p>Instead, the model will always choose—due to its lack of information—to predict an <em>averaged, generic</em> dog face. This actually happens anytime we use the mean squared error as a loss function: if you think of a regular <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1024px-Linear_regression.svg.png" target="_blank">univariate linear regression</a>, the prediction is a line that goes kind of in between the training data points. This way the prediction error is never very high; <em>on average</em>, the model always does a relatively good job. But it does not focus on predicting any point particularly better than the rest.</p>
<p>The same is happening here: since the model does not have good information to work with (only random noise), the best it can do is to create a generic dog face; which is basically the average of many dog faces seen during training. The end result is very poor, but our model <em>thinks</em> that it is doing a good job! It is not taking the risk of generating a specific dog face. To the model’s eyes, the prediction it generated is way better than if it perfectly predicted any of the three dog faces we have in the diagram: predicting any of those out of pure random noise would be <em>too risky</em>, and it would violate the principle of “doing good on average, without overfitting” that mean squared error dictates.</p>
<p>This shows the <strong>disconnection between how we train our model and the task we want it to perform</strong>. We obviously would prefer to obtain any of the three dog faces out of our generative model, instead of a blurry average. These kinds of disconnections are common in generative AI, and they mostly happen because virtually all generative models are just discriminative under the hood—but somewhere in the process we alter their behavior and/or how we use them to obtain generative properties out of them. Other examples of such disconnections are LLM <em>hallucinations</em> or the <em>mode collapse</em> phenomenon that affects GANs.</p>
<p><br> In order to fix the issue, we will just undergo an iterative process: progressively denoising the image instead of trying to do it in a single step. We will perform many small jumps instead of a single large one, just as we do in the forward process if we don’t use the Nice™ property <a href="#fp3">(see back here)</a>. This will effectively have the effect of <em>fooling</em> the model: <em>steering</em> its subsequent predictions so it makes riskier predictions without it knowing. We will see in a moment how this works.</p>
<p>So, instead of trying to jump directly to <span class="math inline">\(\hat{\mathbf{x}}_0\)</span>, we will just perform a small jump in that direction. We will just predict what <span class="math inline">\(\mathbf{x}_{T-1}\)</span> should be like based on <span class="math inline">\(\mathbf{x}_T\)</span>. Here it is:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_sampling_process_4.png" class="withborder img-fluid figure-img"></p>
<figcaption>Small jump in the predicted direction</figcaption>
</figure>
</div>
<p><br> As represented by the black arrow.</p>
<p>Given that we have jumped to a new point, if we now repeat these steps (predict new direction and perform a small jump) we will end up with some image after <span class="math inline">\(T\)</span> steps.</p>
<p>After any step we end up with a new, slightly denoised image. However, the model <em>doesn’t have memory between jumps</em>—meaning that it does not know that the image used to predict the next jump comes from a previous jump. For the model, a partial “image” predicted out of pure noise might as well be a “real” image that was made partially noisy with the Nice™ property in the forward process; it does not know that it comes from pure random noise. This is effectively how we <em>fool</em> the model and force it to generate more non-genernic, <em>risky</em> images: at the beginning of each step we are basically telling the model: <em>assuming that this image <span class="math inline">\(\mathbf{x}_{t}\)</span> is a partially noisy image generated from a true, real <span class="math inline">\(\mathbf{x}_0\)</span>, you have now to predict the direction we should jump to get to <span class="math inline">\(\mathbf{x}_{t-1}\)</span></em>. This has the effect of making the model slowly “deviate” from what would have been the single step, generic prediction <span class="math inline">\(\hat{\mathbf{x}}_0\)</span>: creating a snowball effect where the model incrementally predicts more and more non-generic, non-averaged, <em>riskier</em>, more biased images (more similar to one specific dog than to the rest of them).</p>
<p>In fact, to further encourage the appearence of these “deviations” we can already answer the second question we had about the sampling algorithm:</p>
<blockquote class="blockquote">
<p><em>2. What on Earth is <span class="math inline">\(\sigma_t \mathbf{z}\)</span> and why is it there? It is adding back Normal noise to the image in the middle of our denoising process! For all the trouble we got to learn a model capable of denoising, <strong>why are we adding noise back again</strong> in order to denoise an image??</em></p>
</blockquote>
<p>Indeed, we will add noise right after each prediction + jump, which will effectively make us perform a <em>random extra jump</em> in each iteration. Here it is:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_sampling_process_5.png" class="withborder img-fluid figure-img"></p>
<figcaption>Adding noise during sampling</figcaption>
</figure>
</div>
<p><br> So each sampling iteration involves using the model to predict a direction, performing a jump in that direction, and then randomly performing an extra-jump based on some randomly generated noise <span class="math inline">\(\mathbf{z}\)</span>, which is the orange arrow as seen in the diagram above.</p>
<p>That <em>extra-noise</em> that is added has the effect of making the sampling process “deviate” even more from <span class="math inline">\(\hat{\mathbf{x}}_0\)</span>.</p>
<p>We can now note the following crucial statement: <strong>Our goal is not to accurately reconstruct an original image; all we want is to generate good-looking images out of random noise</strong>. We train our model to learn to reconstruct images just as a convenient, tractable proxy for the real task we want to perform.</p>
<p>To summarize: it is impossible to generate the perfect, original image out of an <span class="math inline">\(\mathbf{x}_T\)</span> that we created as pure random noise, because there is no such thing as an original image in this case! In fact, we don’t even really want that; all we want is to generate <em>some nice</em> image out of that noise. We therefore create an iterative, gradual process that makes our model randomly “deviate” from creating a generic, averaged dog image. This means that out of pure noise we can end up with any dog breed, depending on the random noise we started with and that extra-noise that we inject in each iteration. Because again, our end goal is to generate good-looking images; not to perfectly reconstruct an image.</p>
<p><br> All that is left is to rinse and repeat for <span class="math inline">\(T\)</span> iterations. For the second iteration we start from <span class="math inline">\(\mathbf{x}_{T-1}\)</span>, and we use our model to predict the jumping direction:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_sampling_process_6.png" class="withborder img-fluid figure-img"></p>
<figcaption>Newly predicted direction for the second iteration</figcaption>
</figure>
</div>
<p><br> If we were now to take this predicted direction and jump straight to what it would be the updated <span class="math inline">\(\hat{\mathbf{x}}_0\)</span>, you can see that it is slightly less blurry than the original <span class="math inline">\(\hat{\mathbf{x}}_0\)</span>: it would be already a bit less generic, more biased towards the Pitbull breed in this case (again, this is totally random).</p>
<p>Nevertheless, we will again perform a small jump in that direction and add random extra-noise <span class="math inline">\(\mathbf{z}\)</span>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diffusion_space/exports/compressed/diagram_sampling_process_7.png" class="withborder img-fluid figure-img"></p>
<figcaption>Jump + extra-noise for the second iteration</figcaption>
</figure>
</div>
<p><br> Yielding a prediction for <span class="math inline">\(\mathbf{x}_{T-2}\)</span>. You can see that in this case the randomness of this new <span class="math inline">\(\mathbf{z}\)</span> makes our prediction move in almost the opposite direction to where the real dog faces are. This is fine: it is part of the “deviating from the average, generic doc face” process.</p>
<p>From this point on, we can just repeat the same procedure until we have finished all <span class="math inline">\(T\)</span> iterations. The final generated image will hopefully be a specific, non-averaged image of a dog! Keep in mind that we won’t end up with an exact copy of one of the dogs in the training dataset either, and that’s fine; our goal is to generate new, realistic-looking dog faces, different from the ones we trained on.</p>
<p>Furthermore, the iterative nature of the sampling algorithm not only helps with getting something else than a blurry, average dog face; it also allows the model to <em>iteratively refine</em> the generated image. During the first iterations the model mostly generates very high-level shapes and base colors (as you can see in the diagram above for <span class="math inline">\(\mathbf{x}_{T-1}\)</span> and <span class="math inline">\(\mathbf{x}_{T-2}\)</span>, where all we can see is some dog-like face shape). However, in the last iterations most of the final image is already done—and it is at this point when the small details start being perceptible: textures, random glares, luminance details, and related. These small details are usually known as <em>high-frequency details</em> in diffusion terminology.</p>
<p><br> And that’s about it. Keep in mind that numerous publications that came after the DDPM paper changed many aspects of the algorithm. For instance:</p>
<ul>
<li>Some diffusion variants do not add this extra-noise <span class="math inline">\(\mathbf{z}\)</span> in the sampling algorithm (such as in <a href="https://arxiv.org/abs/2010.02502" target="_blank">DDIM by Song et al.&nbsp;[2020]</a>)</li>
<li>Other implementations try to predict <span class="math inline">\(\beta_t\)</span> with a model instead of manually fixing its values upfront (for instance in <a href="https://arxiv.org/abs/2102.09672" target="_blank">Nichol &amp; Dhariwal [2021]</a>)</li>
<li>Many variants use different values of <span class="math inline">\(T\)</span> for training and sampling (as seen in the two previous mentioned papers as well. In DDIM they basically “skip” some <span class="math inline">\(t\)</span>s during sampling and jump right from <span class="math inline">\(t-8\)</span> to <span class="math inline">\(t-6\)</span> for instance)</li>
</ul>
<p>Alongside many, many other algorithm modifications that have been presented since 2020.<br><br></p>
<hr>
</section>
</span></section>
<section id="citation" class="level1">
<h1>Citation</h1>
<p>If you would like to cite this post in an academic context, you can use the following BibTeX snippet:</p>
<div id="da28e003-5573-4ff1-aca2-f0e5c09ab440" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="at">@article</span>{sanchez2024diffappendices,</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  title   <span class="op">=</span> <span class="st">"Appendices for lectures on diffusion models"</span>,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  author  <span class="op">=</span> <span class="st">"Sanchez, Laura and Soto, Julio A."</span>,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  year    <span class="op">=</span> <span class="st">"2024"</span>,</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  month   <span class="op">=</span> <span class="st">"Nov"</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  url     <span class="op">=</span> <span class="st">"https://julioasotodv.github.io/ie-c4-466671-diffusion-models/Appendices</span><span class="sc">%20f</span><span class="st">or</span><span class="sc">%20le</span><span class="st">ctures</span><span class="sc">%20o</span><span class="st">n</span><span class="sc">%20d</span><span class="st">iffusion%20models.html"</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br><br></p>
<hr>
</section>
<section id="references" class="level1">
<h1>References</h1>
<div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-choi2020starganv2" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Yunjey Choi, Youngjung Uh, Jaejun Yoo, and Jung-Woo Ha. 2020. StarGAN v2: Diverse image synthesis for multiple domains. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em>, 2020.</div>
</div>
<div id="ref-dieleman2023geometry" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Sander Dieleman. 2023. The geometry of diffusion guidance. Retrieved from <a href="https://sander.ai/2023/08/28/geometry.html">https://sander.ai/2023/08/28/geometry.html</a></div>
</div>
<div id="ref-Feller1949OnTT" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">William Feller. 1949. On the theory of stochastic processes, with particular reference to applications. 1949. Retrieved from <a href="https://api.semanticscholar.org/CorpusID:121027442">https://api.semanticscholar.org/CorpusID:121027442</a></div>
</div>
<div id="ref-ho2020denoising" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising diffusion probabilistic models. <em>arXiv preprint arxiv:2006.11239</em> (2020).</div>
</div>
<div id="ref-kingma2013autoencodingvariationalbayes" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. Retrieved from <a href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</a></div>
</div>
<div id="ref-luo2022understandingdiffusionmodelsunified" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">Calvin Luo. 2022. Understanding diffusion models: A unified perspective. Retrieved from <a href="https://arxiv.org/abs/2208.11970">https://arxiv.org/abs/2208.11970</a></div>
</div>
<div id="ref-nichol2021improveddenoisingdiffusionprobabilistic" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">Alex Nichol and Prafulla Dhariwal. 2021. Improved denoising diffusion probabilistic models. Retrieved from <a href="https://arxiv.org/abs/2102.09672">https://arxiv.org/abs/2102.09672</a></div>
</div>
<div id="ref-pmlr-v37-sohl-dickstein15" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. 2015. Deep unsupervised learning using nonequilibrium thermodynamics. In <em>Proceedings of the 32nd international conference on machine learning</em> (<em>Proceedings of machine learning research</em>), 2015. PMLR, Lille, France, 2256–2265. Retrieved from <a href="https://proceedings.mlr.press/v37/sohl-dickstein15.html">https://proceedings.mlr.press/v37/sohl-dickstein15.html</a></div>
</div>
<div id="ref-song2020denoising" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">Jiaming Song, Chenlin Meng, and Stefano Ermon. 2020. Denoising diffusion implicit models. <em>arXiv:2010.02502</em> (2020). Retrieved from <a href="https://arxiv.org/abs/2010.02502">https://arxiv.org/abs/2010.02502</a></div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = true;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/julioasotodv\.github\.io\/ie-c4-466671-diffusion-models");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>2024 - Laura Sánchez &amp; Julio A. Soto</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>
